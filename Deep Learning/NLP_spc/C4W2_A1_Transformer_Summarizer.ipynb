{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lpanigrahi/coursera/blob/main/Deep%20Learning/NLP_spc/C4W2_A1_Transformer_Summarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yuytuIllsv1"
      },
      "source": [
        "\n",
        "# Assignment 2: Transformer Summarizer\n",
        "\n",
        "Welcome to the second assignment of course 4. In this assignment you will explore summarization using the transformer model. Yes, you will implement the transformer decoder from scratch, but we will slowly walk you through it. There are many hints in this notebook so feel free to use them as needed. \n",
        "\n",
        "<img src = \"transformerNews.png\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-3lxSnXRWPx"
      },
      "source": [
        "## Outline\n",
        "\n",
        "- [Introduction](#0)\n",
        "- [Part 1: Importing the dataset](#1)\n",
        "    - [1.1 Encode & Decode helper functions](#1.1)\n",
        "    - [1.2 Defining parameters](#1.2)\n",
        "    - [1.3 Exploring the data](#1.3)\n",
        "- [Part 2: Summarization with transformer](#2)\n",
        "    - [2.1 Dot product attention](#2.1)\n",
        "        - [Exercise 01](#ex01)\n",
        "    - [2.2 Causal Attention](#2.2)\n",
        "        - [Exercise 02](#ex02)\n",
        "    - [2.3 Transformer decoder block](#2.3)\n",
        "        - [Exercise 03](#ex03)\n",
        "    - [2.4 Transformer Language model](#2.4)\n",
        "        - [Exercise 04](#ex04)\n",
        "- [Part 3: Training](#3)\n",
        "    - [3.1 Training the model](#3.1)\n",
        "        - [Exercise 05](#ex05)\n",
        "- [Part 4: Evaluation](#4)\n",
        "    - [4.1 Loading in a trained model](#4.1)\n",
        "- [Part 5: Testing with your own input](#5) \n",
        "    - [Exercise 6](#ex06)\n",
        "    - [5.1 Greedy decoding](#5.1)\n",
        "        - [Exercise 07](#ex07)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4NlfEQhRWPy"
      },
      "source": [
        "<a name='0'></a>\n",
        "### Introduction\n",
        "\n",
        "Summarization is an important task in natural language processing and could be useful for a consumer enterprise. For example, bots can be used to scrape articles, summarize them, and then you can use sentiment analysis to identify the sentiment about certain stocks. Anyways who wants to read an article or a long email today, when you can build a transformer to summarize text for you. Let's get started, by completing this assignment you will learn to:  \n",
        "\n",
        "- Use built-in functions to preprocess your data\n",
        "- Implement DotProductAttention\n",
        "- Implement Causal Attention\n",
        "- Understand how attention works\n",
        "- Build the transformer model\n",
        "- Evaluate your model\n",
        "- Summarize an article\n",
        "\n",
        "As you can tell, this model is slightly different than the ones you have already implemented. This is heavily based on attention and does not rely on sequences, which allows for parallel computing. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "KzUecFzelHlq",
        "outputId": "231c51af-9793-4542-ae05-62a5c2a23234",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "ThQQXo9zlN8J"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_NAME = 'C4W2_A1_Transformer_Summarizer'"
      ],
      "metadata": {
        "id": "3otGOOqtlQGQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WORKING_DIR = os.path.join(os.getcwd(),'drive/MyDrive/coursera',PROJECT_NAME)\n",
        "\n",
        "if not os.path.exists(WORKING_DIR):\n",
        "  %mkdir {WORKING_DIR}\n",
        "  %cd {WORKING_DIR}\n",
        "else:\n",
        "  %cd {WORKING_DIR} "
      ],
      "metadata": {
        "id": "PEV_EP1Elac2",
        "outputId": "06614530-841f-4090-a389-d09e2ccd88e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/coursera/C4W2_A1_Transformer_Summarizer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import jax.tools.colab_tpu\n",
        "# jax.tools.colab_tpu.setup_tpu()"
      ],
      "metadata": {
        "id": "RpblvOkllgSN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# jax.device_count()"
      ],
      "metadata": {
        "id": "jhLcYwFwll_N"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q -U trax"
      ],
      "metadata": {
        "id": "CTrUiZIQlqqj",
        "outputId": "16424099-12a5-40af-9da3-98bf87b6ec9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m637.9/637.9 KB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CChWzW-rEHVb"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import textwrap\n",
        "wrapper = textwrap.TextWrapper(width=70)\n",
        "\n",
        "import trax\n",
        "from trax import layers as tl\n",
        "from trax.fastmath import numpy as jnp\n",
        "\n",
        "# to print the entire np array\n",
        "np.set_printoptions(threshold=sys.maxsize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEL2rvaHRWP4"
      },
      "source": [
        "<a name='1'></a>\n",
        "## Part 1: Importing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83ghGCZQk_nw"
      },
      "source": [
        "Trax makes it easy to work with Tensorflow's datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VInmKSkhEhle"
      },
      "outputs": [],
      "source": [
        "# This will download the dataset if no data_dir is specified.\n",
        "# Downloading and processing can take bit of time,\n",
        "# so we have the data already in 'data/' for you\n",
        "\n",
        "# Importing CNN/DailyMail articles dataset\n",
        "train_stream_fn = trax.data.TFDS('cnn_dailymail',\n",
        "                                 data_dir='data/',\n",
        "                                 keys=('article', 'highlights'),\n",
        "                                 train=True)\n",
        "\n",
        "# This should be much faster as the data is downloaded already.\n",
        "eval_stream_fn = trax.data.TFDS('cnn_dailymail',\n",
        "                                data_dir='data/',\n",
        "                                keys=('article', 'highlights'),\n",
        "                                train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1v53UVEJk_nx"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "## 1.1 Tokenize & Detokenize helper functions\n",
        "\n",
        "Just like in the previous assignment, the cell above loads in the encoder for you. Given any data set, you have to be able to map words to their indices, and indices to their words. The inputs and outputs to your [Trax](https://github.com/google/trax) models are usually tensors of numbers where each number corresponds to a word. If you were to process your data manually, you would have to make use of the following: \n",
        "\n",
        "- <span style='color:blue'> word2Ind: </span> a dictionary mapping the word to its index.\n",
        "- <span style='color:blue'> ind2Word:</span> a dictionary mapping the index to its word.\n",
        "- <span style='color:blue'> word2Count:</span> a dictionary mapping the word to the number of times it appears. \n",
        "- <span style='color:blue'> num_words:</span> total number of words that have appeared. \n",
        "\n",
        "Since you have already implemented these in previous assignments of the specialization, we will provide you with helper functions that will do this for you. Run the cell below to get the following functions:\n",
        "\n",
        "- <span style='color:blue'> tokenize: </span> converts a text sentence to its corresponding token list (i.e. list of indices). Also converts words to subwords.\n",
        "- <span style='color:blue'> detokenize: </span> converts a token list to its corresponding sentence (i.e. string)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "djTiSLcaNFGa"
      },
      "outputs": [],
      "source": [
        "def tokenize(input_str, EOS=1):\n",
        "    \"\"\"Input str to features dict, ready for inference\"\"\"\n",
        "  \n",
        "    # Use the trax.data.tokenize method. It takes streams and returns streams,\n",
        "    # we get around it by making a 1-element stream with `iter`.\n",
        "    inputs =  next(trax.data.tokenize(iter([input_str]),\n",
        "                                      vocab_dir='vocab_dir/',\n",
        "                                      vocab_file='summarize32k.subword.subwords'))\n",
        "    \n",
        "    # Mark the end of the sentence with EOS\n",
        "    return list(inputs) + [EOS]\n",
        "\n",
        "def detokenize(integers):\n",
        "    \"\"\"List of ints to str\"\"\"\n",
        "  \n",
        "    s = trax.data.detokenize(integers,\n",
        "                             vocab_dir='vocab_dir/',\n",
        "                             vocab_file='summarize32k.subword.subwords')\n",
        "    \n",
        "    return wrapper.fill(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WvhaFbCRWQS"
      },
      "source": [
        "<a name='1.2'></a>\n",
        "\n",
        "## 1.2 Preprocessing for Language Models: Concatenate It!\n",
        "\n",
        "This week you will use a language model -- Transformer Decoder -- to solve\n",
        "an input-output problem. As you know, language models only predict the next\n",
        "word, they have no notion of inputs. To create a single input suitable for\n",
        "a language model, we concatenate inputs with targets putting a separator\n",
        "in between. We also need to create a mask -- with 0s at inputs and 1s at targets -- so that the model is not penalized for mis-predicting the article and only focuses on the summary. See the preprocess function below for how this is done."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "c4rgPxYSRWQS"
      },
      "outputs": [],
      "source": [
        "# Special tokens\n",
        "SEP = 0 # Padding or separator token\n",
        "EOS = 1 # End of sentence token\n",
        "\n",
        "# Concatenate tokenized inputs and targets using 0 as separator.\n",
        "def preprocess(stream):\n",
        "    for (article, summary) in stream:\n",
        "        joint = np.array(list(article) + [EOS, SEP] + list(summary) + [EOS])\n",
        "        mask = [0] * (len(list(article)) + 2) + [1] * (len(list(summary)) + 1) # Accounting for EOS and SEP\n",
        "        yield joint, joint, np.array(mask)\n",
        "\n",
        "# You can combine a few data preprocessing steps into a pipeline like this.\n",
        "input_pipeline = trax.data.Serial(\n",
        "    # Tokenizes\n",
        "    trax.data.Tokenize(vocab_dir='vocab_dir/',\n",
        "                       vocab_file='summarize32k.subword.subwords'),\n",
        "    # Uses function defined above\n",
        "    preprocess,\n",
        "    # Filters out examples longer than 2048\n",
        "    trax.data.FilterByLength(2048)\n",
        ")\n",
        "\n",
        "# Apply preprocessing to data streams.\n",
        "train_stream = input_pipeline(train_stream_fn())\n",
        "eval_stream = input_pipeline(eval_stream_fn())\n",
        "\n",
        "train_input, train_target, train_mask = next(train_stream)\n",
        "\n",
        "assert sum((train_input - train_target)**2) == 0  # They are the same in Language Model (LM)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKFoGsUKSa_I",
        "outputId": "b1bf43f7-f4c9-47ed-c8d8-73a1869833d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single example mask:\n",
            "\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ],
      "source": [
        "# prints mask, 0s on article, 1s on summary\n",
        "print(f'Single example mask:\\n\\n {train_mask}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4uHyCkbSuUo",
        "outputId": "c15d5b1d-64ef-4aa4-9da1-55b49f743d5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single example:\n",
            "\n",
            " It has been claimed that CIA agents on the ground during the deadly\n",
            "attack on the U.S. Consulate in Benghazi twice asked for permission to\n",
            "help Ambassador Chris Stevens and twice were told to stand down.\n",
            "Furthermore sources present during the deadly six-hour assault have\n",
            "said that a desperate last request for military assistance once the\n",
            "CIA themselves came under attack was denied, even though elite\n",
            "counter-terrorism units were only two hours away. And it has been\n",
            "claimed there was full communication between the CIA annex in Benghazi\n",
            "and the U.S. military, casting further doubts on the Obama\n",
            "administration's assertion that there wasn't enough information to\n",
            "deploy forces - deepening the crisis over their handling of the attack\n",
            "on September 11th and its aftermath. Scroll down for video.\n",
            "Revelations: It has been claimed today that CIA operatives at the\n",
            "Benghazi consulate compound repeatedly had their requests for help\n",
            "denied during the deadly assault on September 11. The lethal assault\n",
            "which led to the death of Ambassador Stevens and three other U.S.\n",
            "citizens began at 9.40 p.m. as the U.S Consulate came under fire from\n",
            "hostile Libyan forces. According to Fox News, ex-Navy SEAL Tyrone\n",
            "Woods, who was part of a small team at the CIA annex about a mile from\n",
            "the consulate, asked his superiors if he could go and assist the\n",
            "embattled diplomatic compound. However, they were told to 'stand down'\n",
            "and according to sources who spoke to the news channel were told to\n",
            "'stand down' again after asking for a second time to help Ambassador\n",
            "Stevens and his staff. Ignoring these orders, Woods and two others\n",
            "heroically made their way to the consulate which by now was ablaze and\n",
            "began firing on the attackers. Knowledge: It is unclear who denied the\n",
            "requests of the CIA for special forces teams. The quick reaction force\n",
            "which Woods was part of helped an evacuation of the main building and\n",
            "recovered the body of State Department staff member Sean Smith who had\n",
            "died in the initial attack. However, the team from the CIA annex could\n",
            "not locate Ambassador Stevens and returned to their own base at around\n",
            "midnight where they came under attack themselves. Immediately calling\n",
            "for assistance from Sigonella Air base in Italy which is two hours\n",
            "away, it is claimed that two separate special operations teams and air\n",
            "support were told to wait - despite the gun battle raging for four\n",
            "hours. It is not known who denied the request for help for the CIA\n",
            "operatives on the ground at Benghazi. If true these claims will\n",
            "radically change the perception of the field agents who were operating\n",
            "on the ground in Benghazi. Previously criticised for providing\n",
            "inadequate security for the consulate staff, the new information shows\n",
            "intelligence operatives repeatedly tried to assist and in fact were\n",
            "denied their own requests for outside help. Killed: Ambassador\n",
            "Christopher Stevens (left) died following smoke inhalation, while\n",
            "agent Sean Smith (right) died in a. desperate battle. Heroic: Former\n",
            "Navy SEALs Glen Doherty (left) and Tyrone Woods (right) were killed in\n",
            "a mortar attack. Refuting the Defense Secretary Leon Panetta's claim\n",
            "yesterday that there simply wasn't enough information to responsibly\n",
            "deploy forces to Libya at the time of the attack, sources on the\n",
            "ground claim that communication was open throughout the attack.\n",
            "Indeed, one member of the CIA team who was on the roof of the annex\n",
            "was in possession of a laser to guide aerial targets including drones\n",
            "and repeatedly requested backup from a Specter gunship to take out an\n",
            "attacker firing mortars. According to sources familiar with the\n",
            "situation, the operative had visual contact with the Libyan mortar\n",
            "team and in addition was able to pinpoint positions from where the\n",
            "consulate attackers were firing from. Yesterday Leon Panetta claimed\n",
            "that he and General Martin Dempsey, chairman of the U.S. military's\n",
            "Joint Chiefs of Staff, and General Carter Ham, head of the U.S.\n",
            "military's Africa Command, felt they couldn't 'put forces at risk in\n",
            "that situation.' A CIA operatives request for an AC-130H gunship to\n",
            "take down a Libyan mortar position was denied. Inferno: Armed\n",
            "attackers dumped cans of diesel fuel and set ablaze the consulate's\n",
            "exterior. Siege: The compound came under heavy mortar and gunfire\n",
            "during the attack, which lasted several hours. 'This happened within a\n",
            "few hours and it was really over before, you know, we had the\n",
            "opportunity to really know what was happening,' said Panetta.\n",
            "Furthermore, Fox News has learned that there were two military\n",
            "surveillance drones above the skies of Benghazi during the attack\n",
            "which would have been able to relay real time visuals of the assault\n",
            "to U.S. officials in the White House situation room and the Pentagon.\n",
            "Tyrone Woods and another former Navy SEAL Glen Doherty were killed by\n",
            "a mortar shell at 4 a.m. Libyan time, over six hours after the attack\n",
            "began and just one hour after relief from an American Quick Reaction\n",
            "Force sent from Tripoli had arrive. This new information comes as\n",
            "President Barack Obama's response to the attacks in Libya has become a\n",
            "contentious issue in the hard-fought U.S. presidential race, with\n",
            "Republican opponents raising questions about his administration's\n",
            "truthfulness and competence. Obama supporters have in turn accused\n",
            "Republicans of making unfounded accusations in an effort to score\n",
            "political points from the death of a U.S. ambassador and the three\n",
            "others killed in the Benghazi attack. Flames, grenades and gunfire: A\n",
            "burnt-out car in front of the U.S. consulate. The Speaker of the House\n",
            "of Representatives, Republican John Boehner, asked in a letter to\n",
            "Obama on Thursday about whether military options and assets were\n",
            "offered 'during and in the immediate aftermath of the terrorist\n",
            "attack.' 'Can you explain what options were presented to you or your\n",
            "staff, and why it appears assets were not allowed to be pre-\n",
            "positioned, let alone utilized?' Boehner asked. Defense Secretary Leon\n",
            "Panetta told Pentagon reporters that U.S. forces were on a heightened\n",
            "state of alert already because of the 11th anniversary of the\n",
            "September 11, 2001, attacks on New York and Washington by al Qaeda. In\n",
            "the aftermath of the attack, Panetta reminded reporters that the\n",
            "Pentagon deployed a Marine fleet anti-terrorist security team to\n",
            "Tripoli and had Navy ships off the coast. 'And we were prepared to\n",
            "respond to any contingency. And certainly had forces in place to do\n",
            "that,' he said. Elite team: As the U.S. consulate in Benghazi. came\n",
            "under a devastating attack last month, a rescue team of elite.\n",
            "soldiers was denied the opportunity to assist the CIA who had come\n",
            "under attack. The administration initially attributed the violence to\n",
            "protests over an anti-Islam film and said it was not premeditated.\n",
            "Obama and other officials have since said the incident was a\n",
            "deliberate terrorist attack. U.S. Secretary of State Hillary Clinton\n",
            "has attributed the shifting explanation to 'the fog of war.' A State\n",
            "Department email made public this week showed that two hours after the\n",
            "attack on the U.S. diplomatic mission compound in Benghazi, the\n",
            "Department's Operations Center advised officials at various U.S.\n",
            "agencies that a militant group called Ansar al-Sharia had claimed\n",
            "credit on Twitter and Facebook for the attacks. U.S. officials,\n",
            "including Clinton, on Wednesday said that such Internet postings did\n",
            "not constitute hard evidence of who was responsible for the attacks.\n",
            "The State Department has set up an independent review board to\n",
            "investigate the background and response to the attacks. The U.S.\n",
            "Senate intelligence committee on Thursday said it will hold hearings\n",
            "in November - after the November 6 presidential election - on security\n",
            "and intelligence issues raised by the September 11 attack in\n",
            "Libya.<EOS><pad>Revelationsshed new light on the effectiveness of the\n",
            "CIA at Benghazi and the level of support they were given. When the CIA\n",
            "annex come under attack the field agents were denied a request for\n",
            "military help despite a counter terrorism team being two hours away in\n",
            "Italy. There was full communication between operatives on the ground\n",
            "and headquarters - with the ability to laser guide drones, planes or\n",
            "special forces to enemy targets.<EOS>\n"
          ]
        }
      ],
      "source": [
        "# prints: [Example][<EOS>][<pad>][Example Summary][<EOS>]\n",
        "print(f'Single example:\\n\\n {detokenize(train_input)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4sDS1WIVaYG"
      },
      "source": [
        "<a name='1.3'></a>\n",
        "\n",
        "## 1.3 Batching with bucketing\n",
        "\n",
        "As in the previous week, we use bucketing to create batches of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "oqj1NsbERWQX"
      },
      "outputs": [],
      "source": [
        "# Bucketing to create batched generators.\n",
        "\n",
        "# Buckets are defined in terms of boundaries and batch sizes.\n",
        "# Batch_sizes[i] determines the batch size for items with length < boundaries[i]\n",
        "# So below, we'll take a batch of 16 sentences of length < 128 , 8 of length < 256,\n",
        "# 4 of length < 512. And so on. \n",
        "boundaries =  [128, 256,  512, 1024]\n",
        "batch_sizes = [16,    8,    4,    2, 1]\n",
        "\n",
        "# Create the streams.\n",
        "train_batch_stream = trax.data.BucketByLength(\n",
        "    boundaries, batch_sizes)(train_stream)\n",
        "\n",
        "eval_batch_stream = trax.data.BucketByLength(\n",
        "    boundaries, batch_sizes)(eval_stream)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6M5OA8QRWQb",
        "outputId": "db09a377-c1bf-4d5a-f248-8a96b1c2b07a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1618)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# Every execution will result in generation of a different article\n",
        "# Try running this cell multiple times to see how the length of the examples affects the batch size\n",
        "input_batch, _, mask_batch = next(train_batch_stream)\n",
        "\n",
        "# Shape of the input_batch\n",
        "input_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjNOlljxTGuQ",
        "outputId": "efdd6df7-4e04-4205-a857-adb6dc6c4dc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1680 11703  6133 12461  5485   213  1698  1320   306   527  5323 10366\n",
            "  6623     4    78  2613     2  4874   809   518   373   101   186   501\n",
            " 25765  1423     7     5  1098  2284   412   103 18766     5   320  1798\n",
            "   213  7322  6682   132   256    74   635  1492     3     9 12758  1205\n",
            "    28 16233 11085  2137   542    28  5955   700   145   213  1859 14183\n",
            "  1807     2    28   194   102    28 14131   809  5323 10366  6623     4\n",
            "     7     5   548  1973   947  1343   441   101   186  6531   809   518\n",
            "  1120     3 20900 18250    58  6857   132     2    28 14380  1019   213\n",
            "   296     7     5  1080  2694  2684     2   793   213   205     6   655\n",
            "   782  2684  3513    27  9293  8560   100   285   148 19181   400    25\n",
            "  8409  2860  1133 27634     4    56  4303     2  1480  1353 22793  2741\n",
            "  2935  1019   213   422   527 19101  1019   119  2006     7     5 17203\n",
            "     2   229    36    44  1913   691 17362   320   552    28  2439   979\n",
            "     2  3531   558 22756   186 16130     2   186 17082   866  6827  5314\n",
            "   186  7740   132  1320   773  4617 27634   391   127    28  1602  2613\n",
            "   691  1423     7     5  3913  3973  2734  1133 27634     4   129    39\n",
            "    19   179   246   186    39   952    89  5306   186  2762  6352 27634\n",
            "   391   214 17362     2   213  7989     7     5  1602   127     2  4195\n",
            "   285   106   163  2443   669 27634     4    49    86  1151  4194   691\n",
            "  3444  1338 27634   391  3840   213   566   289     3     9 15402  6682\n",
            "     3   321    36  2663  2269  1019   213  5323 10366  6623     4 11177\n",
            "     5     2    35    41  1841   329   711   102   213  1299   527    28\n",
            " 19796   279 18597   330   260 10966    21  1740   320 17201     4   213\n",
            "   418  2984  6401  7322  6682   285  1977    78   754   112     3   597\n",
            "  2780   965   699   821  9979     4 18462   213 10621   627   412   669\n",
            " 27634     4    28 21822  6616   478  1287    78 13379   101  1133 27634\n",
            "     4     9  1146   566  1028 12522   156   132  9493   114 15863    16\n",
            "   824  6479  7070   114  1258  4617 27634   391  9979     4   127   132\n",
            "    28  1602     2  4195   285    22  1113  1320   699 19717 12366   320\n",
            "  4413 13243  5358  1204   412   110   412   669 27634     4    89  3594\n",
            "   132   213  1320  1882   320  4684  2603   186  4182  2022   132  2984\n",
            "  6401  4172 27634   391  5674     2   213   257   366  1763    50   669\n",
            " 27634     4   444   291   320   213  1320   266   132  1098 19101  1019\n",
            "   213  2984  6401  2780  2022  4617 27634   391   276  3283   751 17984\n",
            "  1091  8963 20917     4 18345   279   127   132    28  1602  1133 27634\n",
            "     4   129    62  3857   213  1171  1019  4426  4212  1019   213  1646\n",
            "   527   213  3740     2 18130     5     2   186    54  2513  4617 27634\n",
            "   391 18345   279   127     3  5323 10366  6623     4   229    28   407\n",
            "  3620 12518   132  1698  1423   186    28   548  6106   340  1019   101\n",
            "  8549   691  1973   320  2984  6401    78   213  1168  2327     2   141\n",
            "    95  2719  1059     8  4598    65 15261    12   320   213 10739     3\n",
            "  1888   194     2  2659   527  6672   147   213   947   132   213   306\n",
            "   640   316 12055 19544  1600     3  1162 11177     5   132    72   390\n",
            "     3  7284 12467  1838   213  1610  2613  1606   213 15626    17  5067\n",
            "   527    28  2498 16233 11085  2137     2  1248 12187  2540   239   103\n",
            "     3     9   910   527   213 14131  6603   558    64   213  5363   527\n",
            "   213  2137     2   412   110   412  3778   527   329  3020  1542     3\n",
            "   348   518   705   101    25   831   320  1151  6531     2  1248   329\n",
            "   132  1839  1785     2   176    36    99     6   984     6   292   966\n",
            "     2  3513    27  9293  8560   100   831     3  4439    78   213 12467\n",
            "     2   213 14131  1472   320    18  1841   132   213   179   605   527\n",
            "   213  2137     3     9  1080  2694  2684   127   103  5435   213 12758\n",
            "  1353   284   236   691    28  1718  6133 17445     4     3 25783   692\n",
            "   127   213  1973   947 14131  1681    43  1472   320    18    46  1768\n",
            "   691    28  6133 17445     4     3  6857   132   793  3513    27  9293\n",
            "  8560   100   285  2182  3687    39  1151  1526    64    78   213  1199\n",
            "   527   213   947 17445     4     2  1779   149   213  4026   527   546\n",
            "  7728     8   137 15062 20462    12   527 14362   189   132    28  2993\n",
            "  2522 10924  6709  7633     3 25783   692   127    41    43   233   163\n",
            " 16963 19614    17 23201    14   809   213  1610     3  7284   576  1838\n",
            "   163   872  1098  4701  1606    28  1917  5908  1400  1599  2754  1494\n",
            "   320  1151   213   548  4322   527   213   150     6   488  1384   474\n",
            "     2  1005   691    28  8467  4949   527  5805  1083    64   527 25895\n",
            "    17  3778     3  1423     7     5  1098  1901     3    34   484     2\n",
            "  3604 10433  8627  5193   473     2   213  1299   527   213 19796   279\n",
            "   260 18733    93 21764   587     2   973    28   846  1602   132  1480\n",
            "    22 16613    17   320 16075 14276   151   669 27634     4  2461  1017\n",
            " 27634   391   320 17201     4   213   584   809  2984  6401     3     9\n",
            "   184    10    59     3   303   676  9900   213 18733    93 21764   587\n",
            "    28  1255  8409   260   186    23  8175    28 14066   527    61   320\n",
            "   281    65   446  1019   215   971   320   213  1154   527  8627  5193\n",
            "   473     3     9   303   676   127  8627  5193   473  2366    28  6133\n",
            " 12461   872   213 19796   279 12970  2734   132   389   460     3   405\n",
            "   260    43  2663  2269  1019   213   421 12461   527 13510 12433 13582\n",
            "    79  6493   132  4792   285  1343  1513   101     2   213   387 10621\n",
            "   627   527   213  4792 24649   285  1343   668   186   213   460 12461\n",
            "   527   213   208     6  1869 13559  2775  9170  1973   132  1480   705\n",
            "   101   710     3    34   560     2    28 17445     4  6603   558    61\n",
            "    28  6683  2137   132  5323 10366  6623     4     2  4874   635   101\n",
            "   186  2281 26523     4    44    74   286   469     3  1320   564   831\n",
            "   285    28  1361 22918     4  6133 17445     4  1838   213  1320   606\n",
            "   527  2669  7552   163  1353  1478  1019   285  1287  1133 27634     4\n",
            "  1135   527   213 13139     5  1478  1019  8409  2860   132  1423    95\n",
            "   213   220  2593    76   176  1361  6133 17445     5  1779    18   576\n",
            "   160   132   247  2860  9420   809   518  6102   121  1056   254   426\n",
            "   591    76    18   413  1838  2669  7552   163  4617 27634   391  3513\n",
            "    27  9293  8560   100   831  2613     3     9    72   506   313   936\n",
            "   213  1633 15666    78 10621   627  1449  6932   132  2669  7552   163\n",
            "   171  1083   320   213   257   366     2   186    36   527   105  3198\n",
            "   213   201   213   104   171   213  1287  1133 27634     4 13888   997\n",
            " 22918     4   535  6118   320   213   489   214   213  1320   205   169\n",
            "    18   196  8352  4241     2   186  1435   525    44  1050     2   132\n",
            "  2669  7552   163    74   132 19796  4438    28  4617 27634   391  8539\n",
            "    47  3186    78     2  1661  2907   809   213  2556   751     2  1113\n",
            "   132    28 14607    10   394  5656     3   397   439  1151   936   213\n",
            "  2860    98 12366    23  3101   285   213  2984  6401   584    39  1151\n",
            "  2603   186  1098    39  1151  8058     3 13868     5   320  2984  6401\n",
            "   186   213  2605   201  1435 13463   320 19583  1098 11658     2   186\n",
            "  2245  5170  7689  1435 16112  1133 27634     4    56    39   934  1151\n",
            "    36   527   213    94  1181  6682   320   962   273   412    28 18130\n",
            "     4   186  2040   213  2022   166   527   213 22270 18243     4  8358\n",
            "   527  1098  4617 27634   391  3837 13595     3  1096 16087    75   527\n",
            "   119   262   793 14607    78  2613     3  1225  1085   527  1423     3\n",
            "   342     2   213  5323 10366  6623     4 19181   400  1606   213  1901\n",
            "   285  1320  1882   882   132 20333   213  1272   527   213   296 10909\n",
            "  4183 17274     4   132   213   438 18733    93     3   449   606   803\n",
            " 19796  4438    28     2  4872  1423  4562    72  8125   214 18597   330\n",
            "  4206     2   186  2669  7552   163     3   512  8058  1098   239  2984\n",
            "  6401   838     2 17362  1435  2162   320  1151  7310    78    54  1085\n",
            "   527   213   438 18733    93   186  1698  1423     3  3513    27  9293\n",
            "  8560   100   831    28  1081  7086  1343   150   101    78  2102   132\n",
            "  7622  3717  6345  8945   132  1698  1423     2  2685  9265  1059     8\n",
            " 21556 15261    12  1077   527  2984  6401  1133 27634     4 25355   114\n",
            "   124    33   962    18    28  8409   260   413    64   186   476   948\n",
            "   129     7   165   416   320  1124   186 17201     4    97   584 22137\n",
            " 27634   391 14607   404  1098 16973 19835     4 12444   250   127  2613\n",
            "  1133 27634     4   312    67 17664     6   582 20077   535   191    97\n",
            "  2548   527  3234     2    33     7   183   540   320   245   105   809\n",
            "    31  1032  4172 27634   391     9   503   285   213 17445     5  1435\n",
            " 11713  3061   229   669 27634     4    19   913    78  2780   965 18417\n",
            "     5   186  1098  1631  4617 27634   391   131   969     3 26481    45\n",
            "  1435   669 27634     4    94  6754 27634   391  7511  1772   111   213\n",
            "  2780  5317   186   213   956   527    31   678     2   131   127     3\n",
            " 12444   250     2  1779 16022  1248  2363  1631   171   213  6682   132\n",
            " 11435   132   645     2   127  1098  1631    38    95   213   175    39\n",
            "  1151  4823  1423  1019  2166   215  2685    97  2860     2   176   647\n",
            "    77    25   116 12302   400   181 11080   627     3   207     7   371\n",
            "    43  2005  2685  2754   215  1320  3885    23    78   213  7719   527\n",
            "  8409   535   320  6909   236   501  2860    10     1     0   184    10\n",
            "    59     3 25374     4   465 18130     5    39   882  8058  6682  1098\n",
            "  4172 27439  6774  1628  1423     7     5  1255  7989 16613    17    28\n",
            "   901   669 27634     4  5306 27634   391  6352   214  8155  4172 27439\n",
            "  6774  1628  1162  8409 10621   627  1205  5323 10366  6623     4     2\n",
            "  4874    44    74   286   101  4172 27439  6774  1628     9  2860  1689\n",
            "  2514  2685  1098   809   213  6682   132   754    10     1]\n"
          ]
        }
      ],
      "source": [
        "# print corresponding integer values\n",
        "print(input_batch[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD-72TENV2Jk"
      },
      "source": [
        "Things to notice:\n",
        " - First we see the corresponding values of the words.\n",
        " - The first 1, which represents the `<EOS>` tag of the article.\n",
        " - Followed by a 0, which represents a `<pad>` tag.\n",
        " - After the first 0 (`<pad>` tag) the corresponding values are of the words that are used for the summary of the article.\n",
        " - The second 1 represents the `<EOS>` tag for the summary.\n",
        " - All the trailing 0s represent `<pad>` tags which are appended to maintain consistent length (If you don't see them then it would mean it is already of max length)\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu05ZwbWTE6P",
        "outputId": "b138a2d7-1399-476b-dd66-5f0294d5db1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Article:\n",
            "\n",
            " Another suspected suicide bombing struck the southern Russian city of\n",
            "Volgograd on Monday, killing at least 14 people and further\n",
            "highlighting Russia's security challenges as it prepares to host the\n",
            "Winter Olympics in less than six weeks. The explosion hit a trolleybus\n",
            "near a busy market during the morning rush hour, a day after a blast\n",
            "at Volgograd's main train station killed 17 people and wounded at\n",
            "least 35. Vladmir Markin, a spokesman for the country's federal\n",
            "investigation agency, told the state-run news agency RIA Novosti that\n",
            "both explosions were terrorist attacks. \"This strike, which was\n",
            "cynically planned for the period of preparations for New Year's\n",
            "celebrations, is one more attempt by terrorists to open a domestic\n",
            "front, sow panic and chaos, and trigger religious strife and conflicts\n",
            "in Russian society,\" said a statement Monday by Russia's Foreign\n",
            "Affairs Ministry. \"We will not back down and will continue our tough\n",
            "and consistent offensive\" against terrorists, the ministry's statement\n",
            "said, adding that such an enemy \"can only be stopped by joint efforts\"\n",
            "involving the international community. The approaching Olympics. No\n",
            "one claimed responsibility for the Volgograd blasts, but they occurred\n",
            "several months after the leader of a Chechen separatist group pledged\n",
            "violence to disrupt the 2014 Sochi Winter Olympics that begin on\n",
            "February 7. International Olympic Committee President Thomas Bach\n",
            "condemned the bombings as \"a despicable attack on innocent people.\n",
            "\"The entire international movement joins me in utterly condemning this\n",
            "cowardly act,\" Bach said in a statement, adding that he wrote Russian\n",
            "President Vladimir Putin to express condolences as well as \"our\n",
            "confidence in the Russian authorities to deliver safe and secure Games\n",
            "in Sochi.\" Meanwhile, the United States offered its \"full support to\n",
            "the Russian government in security preparations for the Sochi Olympic\n",
            "Games,\" National Security Council spokeswoman Caitlin Hayden said in a\n",
            "statement. \"We would welcome the opportunity for closer cooperation\n",
            "for the safety of the athletes, spectators, and other participants,\"\n",
            "Hayden said. Volgograd is a major rail hub in southern Russia and a\n",
            "main transit point for people traveling by train to Sochi on the Black\n",
            "Sea, just over 400 miles (645 kilometers) to the southwest. Each day,\n",
            "thousands of passengers use the station in the city once called\n",
            "Stalingrad. Two blasts in two days. Video footage from the scene\n",
            "Monday showed the twisted shell of a blue trolleybus, with debris\n",
            "spread around it. The impact of the blast blew out the roof of the\n",
            "bus, as well as windows of several nearby houses. At least 28 people\n",
            "were reported to be wounded, with several in serious condition,\n",
            "including one 6-month-old child, RIA Novosti reported. Based on the\n",
            "footage, the blast appeared to have occurred in the back half of the\n",
            "bus. The federal investigation agency said it believes the explosion\n",
            "was set off by a male suicide bomber. Investigators said the train\n",
            "station blast Sunday also appeared to have been caused by a suicide\n",
            "bomber. Markin told RIA Novosti that DNA testing will be carried out\n",
            "on the remains of the station bomber, who used the equivalent of 22\n",
            "pounds (10 kilograms) of TNT in a device containing shrapnel.\n",
            "Investigators said they also found an unexploded grenade at the scene.\n",
            "Video taken from an outside security camera showed a huge fireball\n",
            "inside what appears to be the main entrance of the three-story stone\n",
            "building, followed by a steady trail of smoke coming out of shattered\n",
            "windows. Russia's security challenge. In July, Doku Umarov, the leader\n",
            "of the Chechen group Caucasus Emirate, released a video statement in\n",
            "which he vowed to unleash \"maximum force\" to disrupt the games at\n",
            "Sochi. The U.S. State Department considers the Caucasus Emirate a\n",
            "foreign terrorist group and has authorized a reward of up to $5\n",
            "million for information leading to the location of Umarov. The State\n",
            "Department said Umarov organized a suicide bombing outside the Chechen\n",
            "Interior Ministry in May 2009. His group also claimed responsibility\n",
            "for the 2011 bombing of Domodedovo Airport in Moscow that killed 36\n",
            "people, the 2010 bombings of the Moscow subway that killed 40 and the\n",
            "2009 bombing of the high-speed Nevsky Express train in which 28 people\n",
            "died. In October, a bomber blew up a passenger bus in Volgograd,\n",
            "killing six people and wounding more than 30 others. Russian media\n",
            "reported that a female Islamist suicide bomber from the Russian region\n",
            "of Dagestan was responsible for that attack. \"Most of the militants\n",
            "responsible for terrorist attacks in Russia over the last decade --\n",
            "including female suicide bombers who have taken part in 20 attacks\n",
            "claiming at least 780 lives since June 2000 -- have come from\n",
            "Dagestan,\" RIA Novosti reported Monday. The two young men behind the\n",
            "Boston Marathon bombings lived briefly in Dagestan before coming to\n",
            "the United States, and one of them visited the area the year before\n",
            "the attack. \"Radical Islamist groups tied to the war against the\n",
            "Russian state now have much deeper roots, and are far more active, in\n",
            "Dagestan than in Chechnya,\" Rajan Menon, senior fellow at the Atlantic\n",
            "Council, wrote in a CNN.com column. What might be behind the attacks?\n",
            "Putin has maintained that the Sochi games will be safe and security\n",
            "will be tight. Visitors to Sochi and the surrounding area are\n",
            "subjected to rigorous security checks, and vehicle license plates are\n",
            "monitored. \"This will probably be one of the most difficult Olympics\n",
            "to actually go as a spectator and watch the Games because of the\n",
            "myriad layers of security,\" Republican Rep. Michael Grimm of New York\n",
            "told CNN on Monday. Other parts of Russia. However, the Volgograd\n",
            "explosions showed the challenge that Russian authorities face in\n",
            "policing the rest of the country amid ongoing unrest in the North\n",
            "Caucasus. That region includes Chechnya, where Russia fought two wars\n",
            "against separatist movements, and Dagestan. With tight security around\n",
            "Sochi itself, terrorists are believed to be focusing on other parts of\n",
            "the North Caucasus and southern Russia. RIA Novosti reported a car\n",
            "bomb killed three people on Friday in Pyatigorsk in southern Russia,\n",
            "about 160 miles (270 kilometers) east of Sochi. \"Rarely do you\n",
            "actually have a terrorist group come out and say, 'We're going to try\n",
            "and disrupt these games,'\" CNN national security analyst Fran Townsend\n",
            "said Monday. \"When al Qaeda-related affinity groups make these sort of\n",
            "statements, you've got to take them at their word.\" The fact that the\n",
            "bombers are targeting transportation is \"not lost on Olympic Committee\n",
            "organizers and security officials,\" she added. Athletes are \"most\n",
            "vulnerable\" when moving between the Olympic Village and the sites of\n",
            "their events, she said. Townsend, who coordinated with Greek officials\n",
            "before the Olympics in Athens in 2004, said security officials all\n",
            "over the world will be asking Russia for detailed information about\n",
            "these attacks, including whether there were any indications or\n",
            "warnings. They'll also ask about what information Russian intelligence\n",
            "has on the capabilities of terrorist groups to pull off further\n",
            "attacks.<EOS><pad>U.S. legislator says spectators will face tight\n",
            "Olympics security. Russia's foreign ministry vowed a continued \"tough\"\n",
            "offensive against terrorism. Two terrorist bombings hit Volgograd,\n",
            "killing more than 30 people. The attacks raised concerns about\n",
            "security at the Olympics in February.<EOS>\n"
          ]
        }
      ],
      "source": [
        "# print the article and its summary\n",
        "print('Article:\\n\\n', detokenize(input_batch[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNFVhgHoncGm"
      },
      "source": [
        "You can see that the data has the following structure:\n",
        "- <span style='color:blue'> [Article] </span> -> `<EOS>` -> `<pad>` -> <span style='color:blue'> [Article Summary] </span> -> `<EOS>` -> (possibly) multiple `<pad>`\n",
        "\n",
        "The loss is taken only on the summary using cross_entropy as loss function. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un8NHIRoj-1W"
      },
      "source": [
        "<a name='2'></a>\n",
        "# Part 2: Summarization with transformer\n",
        "\n",
        "Now that we have given you the data generator and have handled the preprocessing for you, it is time for you to build your own model. We saved you some time because we know you have already preprocessed data before in this specialization, so we would rather you spend your time doing the next steps. \n",
        "\n",
        "You will be implementing the attention from scratch and then using it in your transformer model. Concretely, you will understand how attention works, how you use it to connect the encoder and the decoder.\n",
        "\n",
        "<img src=\"https://github.com/lpanigrahi/coursera/blob/main/Deep%20Learning/NLP_spc/transformer_decoder_zoomin.png?raw=1\">\n",
        "\n",
        "<a name='2.1'></a>\n",
        "## 2.1 Dot product attention \n",
        "\n",
        "Now you will implement dot product attention which takes in a query, key, value, and a mask. It returns the output. \n",
        "\n",
        "<img src =\"dotproduct.png\">\n",
        "\n",
        "\n",
        "Here are some helper functions that will help you create tensors and display useful information:\n",
        "   - `create_tensor`  creates a `jax numpy array` from a list of lists.\n",
        "   - `display_tensor` prints out the shape and the actual tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "-djjwTn9k_n4"
      },
      "outputs": [],
      "source": [
        "def create_tensor(t):\n",
        "    \"\"\"Create tensor from list of lists\"\"\"\n",
        "    return jnp.array(t)\n",
        "\n",
        "\n",
        "def display_tensor(t, name):\n",
        "    \"\"\"Display shape and tensor\"\"\"\n",
        "    print(f'{name} shape: {t.shape}\\n')\n",
        "    print(f'{t}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAalVPoFk_n4"
      },
      "source": [
        "Before implementing it yourself, you can play around with a toy example of `dot product attention` without the softmax  operation. Technically it would not be `dot product attention` without the softmax but this is done to avoid giving away too much of the answer and the idea is to display these tensors to give you a sense of how they look like.\n",
        "\n",
        "The formula for attention is this one:\n",
        "\n",
        "$$\n",
        "\\text { Attention }(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}+{M}\\right) V\\tag{1}\\\n",
        "$$\n",
        "\n",
        "$d_{k}$ stands for the dimension of queries and keys.\n",
        "\n",
        "The `query`, `key`, `value` and `mask` vectors are provided for this example.\n",
        "\n",
        "Notice that the masking is done using very negative values that will yield a similar effect to using $-\\infty $. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0x0HJXwRWQk",
        "outputId": "6564ab4a-b819-4b0f-eb09-2286a50ed89c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query shape: (2, 3)\n",
            "\n",
            "[[1 0 0]\n",
            " [0 1 0]]\n",
            "\n",
            "key shape: (2, 3)\n",
            "\n",
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "\n",
            "value shape: (2, 3)\n",
            "\n",
            "[[0 1 0]\n",
            " [1 0 1]]\n",
            "\n",
            "mask shape: (2, 2)\n",
            "\n",
            "[[ 0.e+00  0.e+00]\n",
            " [-1.e+09  0.e+00]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "q = create_tensor([[1, 0, 0], [0, 1, 0]])\n",
        "display_tensor(q, 'query')\n",
        "k = create_tensor([[1, 2, 3], [4, 5, 6]])\n",
        "display_tensor(k, 'key')\n",
        "v = create_tensor([[0, 1, 0], [1, 0, 1]])\n",
        "display_tensor(v, 'value')\n",
        "m = create_tensor([[0, 0], [-1e9, 0]])\n",
        "display_tensor(m, 'mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oPgZNhNk_n5"
      },
      "source": [
        "**Expected Output:**\n",
        "```CPP\n",
        "query shape: (2, 3)\n",
        "\n",
        "[[1 0 0]\n",
        " [0 1 0]]\n",
        "\n",
        "key shape: (2, 3)\n",
        "\n",
        "[[1 2 3]\n",
        " [4 5 6]]\n",
        "\n",
        "value shape: (2, 3)\n",
        "\n",
        "[[0 1 0]\n",
        " [1 0 1]]\n",
        "\n",
        "mask shape: (2, 2)\n",
        "\n",
        "[[ 0.e+00  0.e+00]\n",
        " [-1.e+09  0.e+00]]\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVR9u4faRWQo",
        "outputId": "f88353bc-a1c7-4767-ef1f-6a77da3dfe59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query dot key shape: (2, 2)\n",
            "\n",
            "[[0.57735026 2.309401  ]\n",
            " [1.1547005  2.8867514 ]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "q_dot_k = q @ k.T / jnp.sqrt(3)\n",
        "display_tensor(q_dot_k, 'query dot key')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltdbMc4Uk_n6"
      },
      "source": [
        "**Expected Output:**\n",
        "```CPP\n",
        "query dot key shape: (2, 2)\n",
        "\n",
        "[[0.57735026 2.309401  ]\n",
        " [1.1547005  2.8867514 ]]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Vt671uP0k_n6",
        "outputId": "0eab6d26-75e5-4a0d-e741-6c9c0bafebaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "masked query dot key shape: (2, 2)\n",
            "\n",
            "[[ 5.7735026e-01  2.3094010e+00]\n",
            " [-1.0000000e+09  2.8867514e+00]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "masked = q_dot_k + m\n",
        "display_tensor(masked, 'masked query dot key')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Frg30WI5k_n6"
      },
      "source": [
        "**Expected Output:**\n",
        "```CPP\n",
        "masked query dot key shape: (2, 2)\n",
        "\n",
        "[[ 5.7735026e-01  2.3094010e+00]\n",
        " [-1.0000000e+09  2.8867514e+00]]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "oeDvNCKNk_n7",
        "outputId": "3a0ca3af-f2fe-4369-ec6b-32fd891838d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "masked query dot key dot value shape: (2, 3)\n",
            "\n",
            "[[ 2.3094010e+00  5.7735026e-01  2.3094010e+00]\n",
            " [ 2.8867514e+00 -1.0000000e+09  2.8867514e+00]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "display_tensor(masked @ v, 'masked query dot key dot value')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhveETTSk_n7"
      },
      "source": [
        "**Expected Output:**\n",
        "```CPP\n",
        "masked query dot key dot value shape: (2, 3)\n",
        "\n",
        "[[ 2.3094010e+00  5.7735026e-01  2.3094010e+00]\n",
        " [ 2.8867514e+00 -1.0000000e+09  2.8867514e+00]]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ea3v9JpAk_n7"
      },
      "source": [
        "In order to use the previous dummy tensors to test some of the graded functions, a batch dimension should be added to them so they mimic the shape of real-life examples. The mask is also replaced by a version of it that resembles the one that is used by trax:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "V4uvQMoIk_n7",
        "outputId": "ccbeaf16-d541-45c4-f210-d881dc5ae816",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query with batch dim shape: (1, 2, 3)\n",
            "\n",
            "[[[1 0 0]\n",
            "  [0 1 0]]]\n",
            "\n",
            "key with batch dim shape: (1, 2, 3)\n",
            "\n",
            "[[[1 2 3]\n",
            "  [4 5 6]]]\n",
            "\n",
            "value with batch dim shape: (1, 2, 3)\n",
            "\n",
            "[[[0 1 0]\n",
            "  [1 0 1]]]\n",
            "\n",
            "boolean mask shape: (2, 2)\n",
            "\n",
            "[[ True  True]\n",
            " [False  True]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "q_with_batch = q[None,:]\n",
        "display_tensor(q_with_batch, 'query with batch dim')\n",
        "k_with_batch = k[None,:]\n",
        "display_tensor(k_with_batch, 'key with batch dim')\n",
        "v_with_batch = v[None,:]\n",
        "display_tensor(v_with_batch, 'value with batch dim')\n",
        "m_bool = create_tensor([[True, True], [False, True]])\n",
        "display_tensor(m_bool, 'boolean mask')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3lALUPrk_n8"
      },
      "source": [
        "**Expected Output:**\n",
        "```CPP\n",
        "query with batch dim shape: (1, 2, 3)\n",
        "\n",
        "[[[1 0 0]\n",
        "  [0 1 0]]]\n",
        "\n",
        "key with batch dim shape: (1, 2, 3)\n",
        "\n",
        "[[[1 2 3]\n",
        "  [4 5 6]]]\n",
        "\n",
        "value with batch dim shape: (1, 2, 3)\n",
        "\n",
        "[[[0 1 0]\n",
        "  [1 0 1]]]\n",
        "\n",
        "boolean mask shape: (2, 2)\n",
        "\n",
        "[[ True  True]\n",
        " [False  True]]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq-uvbyhk_n8"
      },
      "source": [
        "<a name='ex01'></a>\n",
        "### Exercise 01\n",
        "\n",
        "**Instructions:** Implement the dot product attention. Concretely, implement the following equation\n",
        "\n",
        "\n",
        "$$\n",
        "\\text { Attention }(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}+{M}\\right) V\\tag{1}\\\n",
        "$$\n",
        "\n",
        "$Q$ - query, \n",
        "$K$ - key, \n",
        "$V$ - values, \n",
        "$M$ - mask, \n",
        "${d_k}$ - depth/dimension of the queries and keys (used for scaling down)\n",
        "\n",
        "You can implement this formula either by `trax` numpy (trax.math.numpy) or regular `numpy` but it is recommended to use `jnp`.\n",
        "\n",
        "Something to take into consideration is that within trax, the masks are tensors of `True/False` values not 0's and $-\\infty$ as in the previous example. Within the graded function don't think of applying the mask by summing up matrices, instead use `jnp.where()` and treat the **mask as a tensor of boolean values with `False` for values that need to be masked and True for the ones that don't.**\n",
        "\n",
        "Also take into account that the real tensors are far more complex than the toy ones you just played with. Because of this avoid using shortened operations such as `@` for dot product or `.T` for transposing. Use `jnp.matmul()` and `jnp.swapaxes()` instead.\n",
        "\n",
        "This is the self-attention block for the transformer decoder. Good luck!  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "kSauPt0NUl_o"
      },
      "outputs": [],
      "source": [
        "# UNQ_C1\n",
        "# GRADED FUNCTION: DotProductAttention\n",
        "def DotProductAttention(query, key, value, mask):\n",
        "    \"\"\"Dot product self-attention.\n",
        "    Args:\n",
        "        query (jax.interpreters.xla.DeviceArray): array of query representations with shape (L_q by d)\n",
        "        key (jax.interpreters.xla.DeviceArray): array of key representations with shape (L_k by d)\n",
        "        value (jax.interpreters.xla.DeviceArray): array of value representations with shape (L_k by d) where L_v = L_k\n",
        "        mask (jax.interpreters.xla.DeviceArray): attention-mask, gates attention with shape (L_q by L_k)\n",
        "\n",
        "    Returns:\n",
        "        jax.interpreters.xla.DeviceArray: Self-attention array for q, k, v arrays. (L_q by L_k)\n",
        "    \"\"\"\n",
        "\n",
        "    assert query.shape[-1] == key.shape[-1] == value.shape[-1], \"Embedding dimensions of q, k, v aren't all the same\"\n",
        "\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    # Save depth/dimension of the query embedding for scaling down the dot product\n",
        "    depth = query.shape[-1] \n",
        "\n",
        "    # Calculate scaled query key dot product according to formula above\n",
        "    dots = jnp.matmul(query, jnp.swapaxes(key, -1, -2)) / jnp.sqrt(depth)\n",
        "    \n",
        "    # Apply the mask\n",
        "    if mask is not None: # The 'None' in this line does not need to be replaced\n",
        "        dots = jnp.where(mask, dots, jnp.full_like(dots, -1e9))\n",
        "    \n",
        "    # Softmax formula implementation\n",
        "    # Use trax.fastmath.logsumexp of dots to avoid underflow by division by large numbers\n",
        "    # Hint: Last axis should be used and keepdims should be True\n",
        "    # Note: softmax = e^(dots - logsumexp(dots)) = E^dots / sumexp(dots)\n",
        "    logsumexp = trax.fastmath.logsumexp(dots, axis=-1, keepdims=True)\n",
        "\n",
        "    # Take exponential of dots minus logsumexp to get softmax\n",
        "    # Use jnp.exp()\n",
        "    dots = jnp.exp(dots - logsumexp)\n",
        "\n",
        "    # Multiply dots by value to get self-attention\n",
        "    # Use jnp.matmul()\n",
        "    attention = jnp.matmul(dots, value)\n",
        "\n",
        "    ## END CODE HERE ###\n",
        "    \n",
        "    return attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o0K7VWKRWQw",
        "outputId": "407c321c-175d-4560-d327-c7236c7a071a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[[0.8496746 , 0.15032545, 0.8496746 ],\n",
              "              [1.        , 0.        , 1.        ]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "DotProductAttention(q_with_batch, k_with_batch, v_with_batch, m_bool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ13_z7Bk_n9"
      },
      "source": [
        "**Expected Output:**\n",
        "```CPP\n",
        "DeviceArray([[[0.8496746 , 0.15032545, 0.8496746 ],\n",
        "              [1.        , 0.        , 1.        ]]], dtype=float32)\n",
        "```    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y2PSiLVRWQ2"
      },
      "source": [
        "<a name='2.2'></a>\n",
        "\n",
        "## 2.2 Causal Attention\n",
        "\n",
        "Now you are going to implement causal attention: multi-headed attention with a mask to attend only to words that occurred before. \n",
        "\n",
        "<img src = \"causal.png\">\n",
        "\n",
        "In the image above, a word can see everything that is before it, but not what is after it. To implement causal attention, you will have to transform vectors and do many reshapes. You will need to implement the functions below.\n",
        "\n",
        "\n",
        "<a name='ex02'></a>\n",
        "### Exercise 02\n",
        "\n",
        "Implement the following functions that will be needed for Causal Attention:\n",
        "\n",
        "- <span style='color:blue'> compute_attention_heads </span>: Gets an input $x$ of dimension (batch_size, seqlen, n_heads $\\times$ d_head) and splits the last (depth) dimension and stacks it to the zeroth dimension to allow matrix multiplication (batch_size $\\times$ n_heads, seqlen, d_head).\n",
        "- <span style='color:blue'> dot_product_self_attention </span>: Creates a mask matrix with `False` values above the diagonal and `True` values below and calls DotProductAttention which implements dot product self attention.\n",
        "- <span style='color:blue'> compute_attention_output </span>: Undoes compute_attention_heads by splitting first (vertical) dimension and stacking in the last (depth) dimension (batch_size, seqlen, n_heads $\\times$ d_head). These operations concatenate (stack/merge) the heads. \n",
        "\n",
        "Next there are some toy tensors which may serve to give you an idea of the data shapes and opperations involved in Causal Attention. They are also useful to test out your functions! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRH67YcrRWQ3",
        "outputId": "654caf02-d668-44d3-b37c-9128560096b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query matrix (2D tensor) shape: (2, 3)\n",
            "\n",
            "[[1 0 0]\n",
            " [0 1 0]]\n",
            "\n",
            "batch of two (multi-head) collections of query matrices (4D tensor) shape: (2, 2, 2, 3)\n",
            "\n",
            "[[[[1 0 0]\n",
            "   [0 1 0]]\n",
            "\n",
            "  [[1 0 0]\n",
            "   [0 1 0]]]\n",
            "\n",
            "\n",
            " [[[1 0 0]\n",
            "   [0 1 0]]\n",
            "\n",
            "  [[1 0 0]\n",
            "   [0 1 0]]]]\n",
            "\n",
            "one batch of concatenated heads of query matrices (3d tensor) shape: (1, 2, 6)\n",
            "\n",
            "[[[1 0 0 1 0 0]\n",
            "  [0 1 0 0 1 0]]]\n",
            "\n",
            "three batches of concatenated heads of query matrices (3d tensor) shape: (3, 2, 6)\n",
            "\n",
            "[[[1 0 0 1 0 0]\n",
            "  [0 1 0 0 1 0]]\n",
            "\n",
            " [[1 0 0 1 0 0]\n",
            "  [0 1 0 0 1 0]]\n",
            "\n",
            " [[1 0 0 1 0 0]\n",
            "  [0 1 0 0 1 0]]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tensor2d = create_tensor(q)\n",
        "display_tensor(tensor2d, 'query matrix (2D tensor)')\n",
        "\n",
        "tensor4d2b = create_tensor([[q, q], [q, q]])\n",
        "display_tensor(tensor4d2b, 'batch of two (multi-head) collections of query matrices (4D tensor)')\n",
        "\n",
        "tensor3dc = create_tensor([jnp.concatenate([q, q], axis = -1)])\n",
        "display_tensor(tensor3dc, 'one batch of concatenated heads of query matrices (3d tensor)')\n",
        "\n",
        "tensor3dc3b = create_tensor([jnp.concatenate([q, q], axis = -1), jnp.concatenate([q, q], axis = -1), jnp.concatenate([q, q], axis = -1)])\n",
        "display_tensor(tensor3dc3b, 'three batches of concatenated heads of query matrices (3d tensor)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjf3iwiYk_n-"
      },
      "source": [
        "It is important to know that the following 3 functions would normally be defined within the `CausalAttention` function further below. \n",
        "\n",
        "However this makes these functions harder to test. Because of this, these functions are shown individually using a `closure` (when necessary) that simulates them being inside of the `CausalAttention` function. This is done because they rely on some variables that can be accessed from within `CausalAttention`.\n",
        "\n",
        "### Support Functions\n",
        "\n",
        "<span style='color:blue'> compute_attention_heads </span>: Gets an input $x$ of dimension (batch_size, seqlen, n_heads $\\times$ d_head) and splits the last (depth) dimension and stacks it to the zeroth dimension to allow matrix multiplication (batch_size $\\times$ n_heads, seqlen, d_head).\n",
        "\n",
        "**For the closures you only have to fill the inner function.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "q8zIdER_k_n-"
      },
      "outputs": [],
      "source": [
        "# UNQ_C2\n",
        "# GRADED FUNCTION: compute_attention_heads_closure\n",
        "def compute_attention_heads_closure(n_heads, d_head):\n",
        "    \"\"\" Function that simulates environment inside CausalAttention function.\n",
        "    Args:\n",
        "        d_head (int):  dimensionality of heads.\n",
        "        n_heads (int): number of attention heads.\n",
        "    Returns:\n",
        "        function: compute_attention_heads function\n",
        "    \"\"\"\n",
        "\n",
        "    def compute_attention_heads(x):\n",
        "        \"\"\" Compute the attention heads.\n",
        "        Args:\n",
        "            x (jax.interpreters.xla.DeviceArray): tensor with shape (batch_size, seqlen, n_heads X d_head).\n",
        "        Returns:\n",
        "            jax.interpreters.xla.DeviceArray: reshaped tensor with shape (batch_size X n_heads, seqlen, d_head).\n",
        "        \"\"\"\n",
        "        ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "        \n",
        "        # Size of the x's batch dimension\n",
        "        batch_size = x.shape[0]\n",
        "        # Length of the sequence\n",
        "        # Should be size of x's first dimension without counting the batch dim\n",
        "        seqlen = x.shape[1]\n",
        "        # Reshape x using jnp.reshape()\n",
        "        # batch_size, seqlen, n_heads*d_head -> batch_size, seqlen, n_heads, d_head\n",
        "        x = jnp.reshape(x, (batch_size, seqlen, n_heads, d_head))\n",
        "        # Transpose x using jnp.transpose()\n",
        "        # batch_size, seqlen, n_heads, d_head -> batch_size, n_heads, seqlen, d_head\n",
        "        # Note that the values within the tuple are the indexes of the dimensions of x and you must rearrange them\n",
        "        x = jnp.transpose(x, (0, 2, 1, 3))\n",
        "        # Reshape x using jnp.reshape()\n",
        "        # batch_size, n_heads, seqlen, d_head -> batch_size*n_heads, seqlen, d_head\n",
        "        x = jnp.reshape(x, (-1, seqlen, d_head))\n",
        "        \n",
        "        ### END CODE HERE ###\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    return compute_attention_heads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "GMmZ0cSKk_n-",
        "outputId": "e46f564b-fed5-490b-cafa-f535d14bf5ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input tensor shape: (3, 2, 6)\n",
            "\n",
            "[[[1 0 0 1 0 0]\n",
            "  [0 1 0 0 1 0]]\n",
            "\n",
            " [[1 0 0 1 0 0]\n",
            "  [0 1 0 0 1 0]]\n",
            "\n",
            " [[1 0 0 1 0 0]\n",
            "  [0 1 0 0 1 0]]]\n",
            "\n",
            "output tensor shape: (6, 2, 3)\n",
            "\n",
            "[[[1 0 0]\n",
            "  [0 1 0]]\n",
            "\n",
            " [[1 0 0]\n",
            "  [0 1 0]]\n",
            "\n",
            " [[1 0 0]\n",
            "  [0 1 0]]\n",
            "\n",
            " [[1 0 0]\n",
            "  [0 1 0]]\n",
            "\n",
            " [[1 0 0]\n",
            "  [0 1 0]]\n",
            "\n",
            " [[1 0 0]\n",
            "  [0 1 0]]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "display_tensor(tensor3dc3b, \"input tensor\")\n",
        "result_cah = compute_attention_heads_closure(2,3)(tensor3dc3b)\n",
        "display_tensor(result_cah, \"output tensor\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r104Ya9k_n_"
      },
      "source": [
        "**Expected Output:**\n",
        "```CPP\n",
        "input tensor shape: (3, 2, 6)\n",
        "\n",
        "[[[1 0 0 1 0 0]\n",
        "  [0 1 0 0 1 0]]\n",
        "\n",
        " [[1 0 0 1 0 0]\n",
        "  [0 1 0 0 1 0]]\n",
        "\n",
        " [[1 0 0 1 0 0]\n",
        "  [0 1 0 0 1 0]]]\n",
        "\n",
        "output tensor shape: (6, 2, 3)\n",
        "\n",
        "[[[1 0 0]\n",
        "  [0 1 0]]\n",
        "\n",
        " [[1 0 0]\n",
        "  [0 1 0]]\n",
        "\n",
        " [[1 0 0]\n",
        "  [0 1 0]]\n",
        "\n",
        " [[1 0 0]\n",
        "  [0 1 0]]\n",
        "\n",
        " [[1 0 0]\n",
        "  [0 1 0]]\n",
        "\n",
        " [[1 0 0]\n",
        "  [0 1 0]]]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT4PjUyBk_n_"
      },
      "source": [
        "<span style='color:blue'> dot_product_self_attention </span>: Creates a mask matrix with `False` values above the diagonal and `True` values below and calls DotProductAttention which implements dot product self attention."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "15nBDG8Bk_n_"
      },
      "outputs": [],
      "source": [
        "# UNQ_C3\n",
        "# GRADED FUNCTION: dot_product_self_attention\n",
        "def dot_product_self_attention(q, k, v):\n",
        "    \"\"\" Masked dot product self attention.\n",
        "    Args:\n",
        "        q (jax.interpreters.xla.DeviceArray): queries.\n",
        "        k (jax.interpreters.xla.DeviceArray): keys.\n",
        "        v (jax.interpreters.xla.DeviceArray): values.\n",
        "    Returns:\n",
        "        jax.interpreters.xla.DeviceArray: masked dot product self attention tensor.\n",
        "    \"\"\"\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    \n",
        "    # Hint: mask size should be equal to L_q. Remember that q has shape (batch_size, L_q, d)\n",
        "    # NOTE: there is a revision underway with the autograder to tolerate better indexing. \n",
        "    # Until then, please index q.shape using negative values (this is equivalent to counting from right to left)\n",
        "    mask_size = q.shape[-2]\n",
        "\n",
        "    # Creates a matrix with ones below the diagonal and 0s above. It should have shape (1, mask_size, mask_size)\n",
        "    # Notice that 1's and 0's get casted to True/False by setting dtype to jnp.bool_\n",
        "    # Use jnp.tril() - Lower triangle of an array and jnp.ones()\n",
        "    mask = jnp.tril(jnp.ones((1, mask_size, mask_size), dtype=jnp.bool_), k=0)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return DotProductAttention(q, k, v, mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "79L9dn_Ak_n_",
        "outputId": "10dc9260-67d4-4e87-e22b-e75195aa9b6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[[0.        , 1.        , 0.        ],\n",
              "              [0.8496746 , 0.15032543, 0.8496746 ]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "dot_product_self_attention(q_with_batch, k_with_batch, v_with_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8-DEtKxk_oA"
      },
      "source": [
        "**Expected Output:**\n",
        "```CPP\n",
        "DeviceArray([[[0.        , 1.        , 0.        ],\n",
        "              [0.8496746 , 0.15032543, 0.8496746 ]]], dtype=float32)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDIqqI9wk_oA"
      },
      "source": [
        "<span style='color:blue'> compute_attention_output </span>: Undoes compute_attention_heads by splitting first (vertical) dimension and stacking in the last (depth) dimension (batch_size, seqlen, n_heads $\\times$ d_head). These operations concatenate (stack/merge) the heads. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "VRrUXs8_k_oA"
      },
      "outputs": [],
      "source": [
        "# UNQ_C4\n",
        "# GRADED FUNCTION: compute_attention_output_closure\n",
        "def compute_attention_output_closure(n_heads, d_head):\n",
        "    \"\"\" Function that simulates environment inside CausalAttention function.\n",
        "    Args:\n",
        "        d_head (int):  dimensionality of heads.\n",
        "        n_heads (int): number of attention heads.\n",
        "    Returns:\n",
        "        function: compute_attention_output function\n",
        "    \"\"\"\n",
        "    \n",
        "    def compute_attention_output(x):\n",
        "        \"\"\" Compute the attention output.\n",
        "        Args:\n",
        "            x (jax.interpreters.xla.DeviceArray): tensor with shape (batch_size X n_heads, seqlen, d_head).\n",
        "        Returns:\n",
        "            jax.interpreters.xla.DeviceArray: reshaped tensor with shape (batch_size, seqlen, n_heads X d_head).\n",
        "        \"\"\"\n",
        "        ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "        \n",
        "        # Length of the sequence\n",
        "        # Should be size of x's first dimension without counting the batch dim\n",
        "        seqlen = x.shape[1]\n",
        "        # Reshape x using jnp.reshape() to shape (batch_size, n_heads, seqlen, d_head)\n",
        "        x = jnp.reshape(x, ( -1, n_heads, seqlen, d_head))\n",
        "        # Transpose x using jnp.transpose() to shape (batch_size, seqlen, n_heads, d_head)\n",
        "        x = jnp.transpose(x, ( 0, 2, 1 , 3))\n",
        "        \n",
        "        ### END CODE HERE ###\n",
        "        \n",
        "        # Reshape to allow to concatenate the heads\n",
        "        return jnp.reshape(x, (-1, seqlen, n_heads * d_head))\n",
        "    \n",
        "    return compute_attention_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "DJkRqQw-k_oA",
        "outputId": "033e6faf-3dd7-4ab6-e714-13f8b6d6ff2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input tensor shape: (6, 2, 3)\n",
            "\n",
            "[[[1 0 0]\n",
            "  [0 1 0]]\n",
            "\n",
            " [[1 0 0]\n",
            "  [0 1 0]]\n",
            "\n",
            " [[1 0 0]\n",
            "  [0 1 0]]\n",
            "\n",
            " [[1 0 0]\n",
            "  [0 1 0]]\n",
            "\n",
            " [[1 0 0]\n",
            "  [0 1 0]]\n",
            "\n",
            " [[1 0 0]\n",
            "  [0 1 0]]]\n",
            "\n",
            "output tensor shape: (3, 2, 6)\n",
            "\n",
            "[[[1 0 0 1 0 0]\n",
            "  [0 1 0 0 1 0]]\n",
            "\n",
            " [[1 0 0 1 0 0]\n",
            "  [0 1 0 0 1 0]]\n",
            "\n",
            " [[1 0 0 1 0 0]\n",
            "  [0 1 0 0 1 0]]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "display_tensor(result_cah, \"input tensor\")\n",
        "result_cao = compute_attention_output_closure(2,3)(result_cah)\n",
        "display_tensor(result_cao, \"output tensor\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9ZTFn4ek_oB"
      },
      "source": [
        "**Expected Output:**\n",
        "```CPP\n",
        "input tensor shape: (6, 2, 3)\n",
        "\n",
        "[[[1 0 0]\n",
        "  [0 1 0]]\n",
        "\n",
        " [[1 0 0]\n",
        "  [0 1 0]]\n",
        "\n",
        " [[1 0 0]\n",
        "  [0 1 0]]\n",
        "\n",
        " [[1 0 0]\n",
        "  [0 1 0]]\n",
        "\n",
        " [[1 0 0]\n",
        "  [0 1 0]]\n",
        "\n",
        " [[1 0 0]\n",
        "  [0 1 0]]]\n",
        "\n",
        "output tensor shape: (3, 2, 6)\n",
        "\n",
        "[[[1 0 0 1 0 0]\n",
        "  [0 1 0 0 1 0]]\n",
        "\n",
        " [[1 0 0 1 0 0]\n",
        "  [0 1 0 0 1 0]]\n",
        "\n",
        " [[1 0 0 1 0 0]\n",
        "  [0 1 0 0 1 0]]]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQG3wz4Pk_oB"
      },
      "source": [
        "### Causal Attention Function\n",
        "\n",
        "Now it is time for you to put everything together within the `CausalAttention` or Masked multi-head attention function:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjN7bpCIk_oB"
      },
      "source": [
        "<img src = \"masked-attention.png\"> \n",
        "\n",
        "**Instructions:** Implement the causal attention.\n",
        "Your model returns the causal attention through a $tl.Serial$ with the following:\n",
        "\n",
        "- <span style='color:blue'> [tl.Branch](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Branch) </span>: consisting of 3 [tl.Dense(d_feature), ComputeAttentionHeads] to account for the queries, keys, and values.\n",
        "- <span style='color:blue'> [tl.Fn](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.base.Fn)</span>: Takes in dot_product_self_attention function and uses it to compute the dot product using $Q$, $K$, $V$.\n",
        "- <span style='color:blue'> [tl.Fn](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.base.Fn)</span>: Takes in restack_attention_heads to allow for parallel computing.\n",
        "- <span style='color:blue'> [tl.Dense](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense)</span>: Final Dense layer, with dimension `d_feature`.\n",
        "\n",
        "Remember that in order for trax to properly handle the functions you just defined, they need to be added as layers using the [`tl.Fn()`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.base.Fn) function. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "B9Adn6DtRWRG"
      },
      "outputs": [],
      "source": [
        "# UNQ_C5\n",
        "# GRADED FUNCTION: CausalAttention\n",
        "def CausalAttention(d_feature, \n",
        "                    n_heads, \n",
        "                    compute_attention_heads_closure=compute_attention_heads_closure,\n",
        "                    dot_product_self_attention=dot_product_self_attention,\n",
        "                    compute_attention_output_closure=compute_attention_output_closure,\n",
        "                    mode='train'):\n",
        "    \"\"\"Transformer-style multi-headed causal attention.\n",
        "\n",
        "    Args:\n",
        "        d_feature (int):  dimensionality of feature embedding.\n",
        "        n_heads (int): number of attention heads.\n",
        "        compute_attention_heads_closure (function): Closure around compute_attention heads.\n",
        "        dot_product_self_attention (function): dot_product_self_attention function. \n",
        "        compute_attention_output_closure (function): Closure around compute_attention_output. \n",
        "        mode (str): 'train' or 'eval'.\n",
        "\n",
        "    Returns:\n",
        "        trax.layers.combinators.Serial: Multi-headed self-attention model.\n",
        "    \"\"\"\n",
        "    \n",
        "    assert d_feature % n_heads == 0\n",
        "    d_head = d_feature // n_heads\n",
        "\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    \n",
        "    # HINT: The second argument to tl.Fn() is an uncalled function (without the parentheses)\n",
        "    # Since you are dealing with closures you might need to call the outer \n",
        "    # function with the correct parameters to get the actual uncalled function.\n",
        "    ComputeAttentionHeads = tl.Fn('AttnHeads', compute_attention_heads_closure(n_heads, d_head), n_out=1)\n",
        "        \n",
        "\n",
        "    return tl.Serial(\n",
        "        tl.Branch( # creates three towers for one input, takes activations and creates queries keys and values\n",
        "            [tl.Dense(d_feature), ComputeAttentionHeads], # queries\n",
        "            [tl.Dense(d_feature), ComputeAttentionHeads], # keys\n",
        "            [tl.Dense(d_feature), ComputeAttentionHeads], # values\n",
        "        ),\n",
        "        \n",
        "        tl.Fn('DotProductAttn', dot_product_self_attention, n_out=1), # takes QKV\n",
        "        # HINT: The second argument to tl.Fn() is an uncalled function\n",
        "        # Since you are dealing with closures you might need to call the outer \n",
        "        # function with the correct parameters to get the actual uncalled function.\n",
        "        tl.Fn('AttnOutput', compute_attention_output_closure(n_heads, d_head), n_out=1), # to allow for parallel\n",
        "        tl.Dense(d_feature) # Final dense layer\n",
        "    )\n",
        "\n",
        "    ### END CODE HERE ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "5tIIN7sgk_oC",
        "outputId": "529079d7-794f-466d-c211-47b750adad01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Serial[\n",
            "  Branch_out3[\n",
            "    [Dense_512, AttnHeads]\n",
            "    [Dense_512, AttnHeads]\n",
            "    [Dense_512, AttnHeads]\n",
            "  ]\n",
            "  DotProductAttn_in3\n",
            "  AttnOutput\n",
            "  Dense_512\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the causal attention model\n",
        "print(CausalAttention(d_feature=512, n_heads=8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBGxShdCk_oC"
      },
      "source": [
        "**Expected Output:**\n",
        "```CPP\n",
        "Serial[\n",
        "  Branch_out3[\n",
        "    [Dense_512, AttnHeads]\n",
        "    [Dense_512, AttnHeads]\n",
        "    [Dense_512, AttnHeads]\n",
        "  ]\n",
        "  DotProductAttn_in3\n",
        "  AttnOutput\n",
        "  Dense_512\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6zwtPjqRWRJ"
      },
      "source": [
        "<a name='2.3'></a>\n",
        "\n",
        "## 2.3 Transformer decoder block\n",
        "\n",
        "Now that you have implemented the causal part of the transformer, you will implement the transformer decoder block. Concretely you will be implementing this image now.\n",
        "\n",
        "<img src = \"transformer_decoder_1.png\" style = \"height:300px\"> \n",
        "\n",
        "To implement this function, you will have to call the `CausalAttention` or Masked multi-head attention function you implemented above. You will have to add a feedforward which consists of: \n",
        "\n",
        "- <span style='color:blue'> [tl.LayerNorm](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.normalization.LayerNorm) </span>: used to layer normalize\n",
        "- <span style='color:blue'> [tl.Dense](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense) </span>: the dense layer\n",
        "- <span style='color:blue'> [ff_activation](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.activation_fns.Relu) </span>: feed forward activation (we use ReLu) here.\n",
        "- <span style='color:blue'> [tl.Dropout](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dropout) </span>: dropout layer\n",
        "- <span style='color:blue'> [tl.Dense](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense) </span>: dense layer\n",
        "- <span style='color:blue'> [tl.Dropout](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dropout) </span>: dropout layer\n",
        "\n",
        "Finally once you implement the feedforward, you can go ahead and implement the entire block using: \n",
        "\n",
        "- <span style='color:blue'> [tl.Residual](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Residual) </span>: takes in the tl.LayerNorm(), causal attention block, tl.dropout. \n",
        "\n",
        "- <span style='color:blue'> [tl.Residual](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Residual) </span>: takes in the feedforward block you will implement. \n",
        "\n",
        "<a name='ex03'></a>\n",
        "### Exercise 03\n",
        "**Instructions:** Implement the transformer decoder block. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "gKOxnRbp1K5U"
      },
      "outputs": [],
      "source": [
        "# UNQ_C6\n",
        "# GRADED FUNCTION: DecoderBlock\n",
        "def DecoderBlock(d_model, d_ff, n_heads,\n",
        "                 dropout, mode, ff_activation):\n",
        "    \"\"\"Returns a list of layers that implements a Transformer decoder block.\n",
        "\n",
        "    The input is an activation tensor.\n",
        "\n",
        "    Args:\n",
        "        d_model (int):  depth of embedding.\n",
        "        d_ff (int): depth of feed-forward layer.\n",
        "        n_heads (int): number of attention heads.\n",
        "        dropout (float): dropout rate (how much to drop out).\n",
        "        mode (str): 'train' or 'eval'.\n",
        "        ff_activation (function): the non-linearity in feed-forward layer.\n",
        "\n",
        "    Returns:\n",
        "        list: list of trax.layers.combinators.Serial that maps an activation tensor to an activation tensor.\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    \n",
        "    # Create masked multi-head attention block using CausalAttention function\n",
        "    causal_attention = CausalAttention( \n",
        "                        d_model,\n",
        "                        n_heads=n_heads,\n",
        "                        mode=mode\n",
        "                        )\n",
        "\n",
        "    # Create feed-forward block (list) with two dense layers with dropout and input normalized\n",
        "    feed_forward = [ \n",
        "        # Normalize layer inputs\n",
        "        tl.LayerNorm(),\n",
        "        # Add first feed forward (dense) layer (don't forget to set the correct value for n_units)\n",
        "        tl.Dense(d_ff),\n",
        "        # Add activation function passed in as a parameter (you need to call it!)\n",
        "        ff_activation(), # Generally ReLU\n",
        "        # Add dropout with rate and mode specified (i.e., don't use dropout during evaluation)\n",
        "        tl.Dropout(rate=dropout, mode=mode),\n",
        "        # Add second feed forward layer (don't forget to set the correct value for n_units)\n",
        "        tl.Dense(d_model),\n",
        "        # Add dropout with rate and mode specified (i.e., don't use dropout during evaluation)\n",
        "        tl.Dropout(rate=dropout,mode=mode)\n",
        "    ]\n",
        "\n",
        "    # Add list of two Residual blocks: the attention with normalization and dropout and feed-forward blocks\n",
        "    return [\n",
        "      tl.Residual(\n",
        "          # Normalize layer input\n",
        "          tl.LayerNorm(),\n",
        "          # Add causal attention block previously defined (without parentheses)\n",
        "          causal_attention,\n",
        "          # Add dropout with rate and mode specified\n",
        "          tl.Dropout(rate=dropout, mode=mode)\n",
        "        ),\n",
        "      tl.Residual(\n",
        "          # Add feed forward block (without parentheses)\n",
        "          feed_forward\n",
        "        ),\n",
        "      ]\n",
        "    ### END CODE HERE ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "pTiAg1svk_oD",
        "outputId": "1a452ce3-2dd6-4f87-9635-9affbeb9c237",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Serial[\n",
            "  Branch_out2[\n",
            "    None\n",
            "    Serial[\n",
            "      LayerNorm\n",
            "      Serial[\n",
            "        Branch_out3[\n",
            "          [Dense_512, AttnHeads]\n",
            "          [Dense_512, AttnHeads]\n",
            "          [Dense_512, AttnHeads]\n",
            "        ]\n",
            "        DotProductAttn_in3\n",
            "        AttnOutput\n",
            "        Dense_512\n",
            "      ]\n",
            "      Dropout\n",
            "    ]\n",
            "  ]\n",
            "  Add_in2\n",
            "], Serial[\n",
            "  Branch_out2[\n",
            "    None\n",
            "    Serial[\n",
            "      LayerNorm\n",
            "      Dense_2048\n",
            "      Serial[\n",
            "        Relu\n",
            "      ]\n",
            "      Dropout\n",
            "      Dense_512\n",
            "      Dropout\n",
            "    ]\n",
            "  ]\n",
            "  Add_in2\n",
            "]]\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the decoder block\n",
        "print(DecoderBlock(d_model=512, d_ff=2048, n_heads=8, dropout=0.1, mode='train', ff_activation=tl.Relu))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ior9-5Syk_oD"
      },
      "source": [
        "**Expected Output:**\n",
        "```CPP\n",
        "[Serial[\n",
        "  Branch_out2[\n",
        "    None\n",
        "    Serial[\n",
        "      LayerNorm\n",
        "      Serial[\n",
        "        Branch_out3[\n",
        "          [Dense_512, AttnHeads]\n",
        "          [Dense_512, AttnHeads]\n",
        "          [Dense_512, AttnHeads]\n",
        "        ]\n",
        "        DotProductAttn_in3\n",
        "        AttnOutput\n",
        "        Dense_512\n",
        "      ]\n",
        "      Dropout\n",
        "    ]\n",
        "  ]\n",
        "  Add_in2\n",
        "], Serial[\n",
        "  Branch_out2[\n",
        "    None\n",
        "    Serial[\n",
        "      LayerNorm\n",
        "      Dense_2048\n",
        "      Relu\n",
        "      Dropout\n",
        "      Dense_512\n",
        "      Dropout\n",
        "    ]\n",
        "  ]\n",
        "  Add_in2\n",
        "]]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoFv-nfLRWRN",
        "lines_to_next_cell": 0
      },
      "source": [
        "<a name='2.4'></a>\n",
        "## 2.4 Transformer Language Model\n",
        "\n",
        "You will now bring it all together. In this part you will use all the subcomponents you previously built to make the final model. Concretely, here is the image you will be implementing. \n",
        "<img src = \"transformer_decoder.png\" style = \"height:400px\">\n",
        "\n",
        "    \n",
        "<a name='ex04'></a>\n",
        "### Exercise 04\n",
        "**Instructions:** Previously you coded the decoder block. Now you will code the transformer language model. Here is what you will need. \n",
        "\n",
        "- <span style=\"color:blue\"> positional_enconder </span>- a list containing the following layers:\n",
        "    - <span style=\"color:blue\"> [tl.Embedding](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Embedding)\n",
        "    - <span style=\"color:blue\"> [tl.Dropout](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dropout)\n",
        "    - <span style=\"color:blue\"> [tl.PositionalEncoding](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.attention.PositionalEncoding)\n",
        "\n",
        "- A list of `n_layers` <span style=\"color:blue\"> decoder blocks</span>.\n",
        "- <span style=\"color:blue\"> [tl.Serial](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Serial): </span> takes in the following layers or lists of layers:\n",
        "    - <span style=\"color:blue\"> [tl.ShiftRight](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.attention.ShiftRight): </span>: shift the tensor to the right by padding on axis 1.\n",
        "    - <span style=\"color:blue\"> positional_encoder </span>: encodes the text positions.\n",
        "    - <span style=\"color:blue\"> decoder_blocks </span>: the ones you created.\n",
        "    - <span style=\"color:blue\"> [tl.LayerNorm](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.normalization.LayerNorm) </span>: a layer norm.\n",
        "    - <span style=\"color:blue\"> [tl.Dense](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense) </span>: takes in the vocab_size.\n",
        "    - <span style=\"color:blue\"> [tl.LogSoftmax](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.LogSoftmax) </span>: to predict.\n",
        "    \n",
        "Go go go!! You can do it :)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "0yi4LJO1RWRS"
      },
      "outputs": [],
      "source": [
        "# UNQ_C7\n",
        "# GRADED FUNCTION: TransformerLM\n",
        "def TransformerLM(vocab_size=33300,\n",
        "                  d_model=512,\n",
        "                  d_ff=2048,\n",
        "                  n_layers=6,\n",
        "                  n_heads=8,\n",
        "                  dropout=0.1,\n",
        "                  max_len=4096,\n",
        "                  mode='train',\n",
        "                  ff_activation=tl.Relu):\n",
        "    \"\"\"Returns a Transformer language model.\n",
        "\n",
        "    The input to the model is a tensor of tokens. (This model uses only the\n",
        "    decoder part of the overall Transformer.)\n",
        "\n",
        "    Args:\n",
        "        vocab_size (int): vocab size.\n",
        "        d_model (int):  depth of embedding.\n",
        "        d_ff (int): depth of feed-forward layer.\n",
        "        n_layers (int): number of decoder layers.\n",
        "        n_heads (int): number of attention heads.\n",
        "        dropout (float): dropout rate (how much to drop out).\n",
        "        max_len (int): maximum symbol length for positional encoding.\n",
        "        mode (str): 'train', 'eval' or 'predict', predict mode is for fast inference.\n",
        "        ff_activation (function): the non-linearity in feed-forward layer.\n",
        "\n",
        "    Returns:\n",
        "        trax.layers.combinators.Serial: A Transformer language model as a layer that maps from a tensor of tokens\n",
        "        to activations over a vocab set.\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    \n",
        "    # Embedding inputs and positional encoder\n",
        "    positional_encoder = [ \n",
        "        # Add embedding layer of dimension (vocab_size, d_model)\n",
        "        tl.Embedding(vocab_size, d_model),\n",
        "        # Use dropout with rate and mode specified\n",
        "        tl.Dropout(rate=dropout, mode=mode),\n",
        "        # Add positional encoding layer with maximum input length and mode specified\n",
        "        tl.PositionalEncoding(max_len=max_len, mode=mode)]\n",
        "\n",
        "    # Create stack (list) of decoder blocks with n_layers with necessary parameters\n",
        "    decoder_blocks = [ \n",
        "        DecoderBlock(d_model, d_ff, n_heads,\n",
        "                    dropout, mode, ff_activation) for _ in range(n_layers)]\n",
        "\n",
        "    # Create the complete model as written in the figure\n",
        "    return tl.Serial(\n",
        "        # Use teacher forcing (feed output of previous step to current step)\n",
        "        tl.ShiftRight(mode=mode), # Specify the mode!\n",
        "        # Add positional encoder\n",
        "        positional_encoder,\n",
        "        # Add decoder blocks\n",
        "        decoder_blocks,\n",
        "        # Normalize layer\n",
        "        tl.LayerNorm(),\n",
        "\n",
        "        # Add dense layer of vocab_size (since need to select a word to translate to)\n",
        "        # (a.k.a., logits layer. Note: activation already set by ff_activation)\n",
        "        tl.Dense(vocab_size),\n",
        "        # Get probabilities with Logsoftmax\n",
        "        tl.LogSoftmax()\n",
        "    )\n",
        "\n",
        "    ### END CODE HERE ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "lRqDMldGk_oE",
        "outputId": "d9b76230-5f36-41b6-caa5-f821bcea3b45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Serial[\n",
            "  Serial[\n",
            "    ShiftRight(1)\n",
            "  ]\n",
            "  Embedding_33300_512\n",
            "  Dropout\n",
            "  PositionalEncoding\n",
            "  Serial[\n",
            "    Branch_out2[\n",
            "      None\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "        Serial[\n",
            "          Branch_out3[\n",
            "            [Dense_512, AttnHeads]\n",
            "            [Dense_512, AttnHeads]\n",
            "            [Dense_512, AttnHeads]\n",
            "          ]\n",
            "          DotProductAttn_in3\n",
            "          AttnOutput\n",
            "          Dense_512\n",
            "        ]\n",
            "        Dropout\n",
            "      ]\n",
            "    ]\n",
            "    Add_in2\n",
            "  ]\n",
            "  Serial[\n",
            "    Branch_out2[\n",
            "      None\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "        Dense_2048\n",
            "        Serial[\n",
            "          Relu\n",
            "        ]\n",
            "        Dropout\n",
            "        Dense_512\n",
            "        Dropout\n",
            "      ]\n",
            "    ]\n",
            "    Add_in2\n",
            "  ]\n",
            "  LayerNorm\n",
            "  Dense_33300\n",
            "  LogSoftmax\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the Transformer\n",
        "print(TransformerLM(n_layers=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1UCK-v3k_oE"
      },
      "source": [
        "**Expected Output:**\n",
        "```CPP\n",
        "Serial[\n",
        "  ShiftRight(1)\n",
        "  Embedding_33300_512\n",
        "  Dropout\n",
        "  PositionalEncoding\n",
        "  Serial[\n",
        "    Branch_out2[\n",
        "      None\n",
        "      Serial[\n",
        "        LayerNorm\n",
        "        Serial[\n",
        "          Branch_out3[\n",
        "            [Dense_512, AttnHeads]\n",
        "            [Dense_512, AttnHeads]\n",
        "            [Dense_512, AttnHeads]\n",
        "          ]\n",
        "          DotProductAttn_in3\n",
        "          AttnOutput\n",
        "          Dense_512\n",
        "        ]\n",
        "        Dropout\n",
        "      ]\n",
        "    ]\n",
        "    Add_in2\n",
        "  ]\n",
        "  Serial[\n",
        "    Branch_out2[\n",
        "      None\n",
        "      Serial[\n",
        "        LayerNorm\n",
        "        Dense_2048\n",
        "        Relu\n",
        "        Dropout\n",
        "        Dense_512\n",
        "        Dropout\n",
        "      ]\n",
        "    ]\n",
        "    Add_in2\n",
        "  ]\n",
        "  LayerNorm\n",
        "  Dense_33300\n",
        "  LogSoftmax\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRRKnoAdvmJ7"
      },
      "source": [
        "<a name='3'></a>\n",
        "# Part 3: Training\n",
        "\n",
        "Now you are going to train your model. As usual, you have to define the cost function, the optimizer, and decide whether you will be training it on a `gpu` or `cpu`. In this case, you will train your model on a cpu for a few steps and we will load in a pre-trained model that you can use to predict with your own words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1lkVebQRWRV"
      },
      "source": [
        "<a name='3.1'></a>\n",
        "### 3.1 Training the model\n",
        "\n",
        "You will now write a function that takes in your model and trains it. To train your model you have to decide how many times you want to iterate over the entire data set. Each iteration is defined as an `epoch`. For each epoch, you have to go over all the data, using your training iterator.\n",
        "\n",
        "<a name='ex05'></a>\n",
        "### Exercise 05\n",
        "**Instructions:** Implement the `train_model` program below to train the neural network above. Here is a list of things you should do:\n",
        "\n",
        "- Create the train task by calling [`trax.supervised.training.TrainTask`](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.TrainTask) and pass in the following: \n",
        "    - <span style='color:blue'> labeled_data </span> = train_gen\n",
        "    - <span style='color:blue'> loss_fn </span> = [tl.CrossEntropyLoss()](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.metrics.CrossEntropyLoss)\n",
        "    - <span style='color:blue'> optimizer </span> = [trax.optimizers.Adam(0.01)](https://trax-ml.readthedocs.io/en/latest/trax.optimizers.html#trax.optimizers.adam.Adam)\n",
        "    - <span style='color:blue'> lr_schedule </span> = [lr_schedule](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.lr_schedules.warmup_and_rsqrt_decay)\n",
        "\n",
        "\n",
        "- Create the eval task by calling [`trax.supervised.training.EvalTask`](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.EvalTask) and pass in the following: \n",
        "    - <span style='color:blue'> labeled_data </span> = eval_gen\n",
        "    - <span style='color:blue'> metrics </span> = tl.CrossEntropyLoss() and [tl.Accuracy()](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.metrics.Accuracy)\n",
        "    \n",
        "    \n",
        "- Create the training loop by calling [`trax.supervised.Training.Loop`](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.Loop) and pass in the following: \n",
        "    - <span style='color:blue'> TransformerLM </span> \n",
        "    - <span style='color:blue'> train_task </span> \n",
        "    - <span style='color:blue'> eval_task </span> = [eval_task]\n",
        "    - <span style='color:blue'> output_dir</span> = output_dir\n",
        "    \n",
        "You will be using a cross entropy loss, with Adam optimizer. Please read the [Trax](https://trax-ml.readthedocs.io/en/latest/index.html) documentation to get a full understanding. \n",
        "\n",
        "The training loop that this function returns can be runned using the `run()` method by passing in the desired number of steps."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = TransformerLM(mode='train')\n",
        "\n",
        "# Load the pre-trained weights\n",
        "# model.init_from_file('gs://trax-ml/transformer_c4_pretrained_1.3.1/model.pkl.gz', weights_only=True)"
      ],
      "metadata": {
        "id": "rQ0gjmVbv_Vt"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "gM2gpu4xvjtX"
      },
      "outputs": [],
      "source": [
        "from trax.supervised import training\n",
        "\n",
        "# UNQ_C8\n",
        "# GRADED FUNCTION: train_model\n",
        "def training_loop(TransformerLM, train_gen, eval_gen, output_dir = \"~/model\"):\n",
        "    '''\n",
        "    Input:\n",
        "        TransformerLM (trax.layers.combinators.Serial): The model you are building.\n",
        "        train_gen (generator): Training stream of data.\n",
        "        eval_gen (generator): Evaluation stream of data.\n",
        "        output_dir (str): folder to save your file.\n",
        "        \n",
        "    Returns:\n",
        "        trax.supervised.training.Loop: Training loop.\n",
        "    '''\n",
        "    output_dir = os.path.expanduser(output_dir)  # trainer is an object\n",
        "    lr_schedule = trax.lr.warmup_and_rsqrt_decay(n_warmup_steps=1000, max_value=0.01)\n",
        "\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    train_task = training.TrainTask( \n",
        "      labeled_data=train_gen, # The training generator\n",
        "      loss_layer=tl.CrossEntropyLoss(), # Loss function \n",
        "      optimizer=trax.optimizers.Adam(0.01), # Optimizer (Don't forget to set LR to 0.01)\n",
        "      lr_schedule=lr_schedule,\n",
        "      n_steps_per_checkpoint=10\n",
        "    )\n",
        "\n",
        "    eval_task = training.EvalTask( \n",
        "      labeled_data=eval_gen, # The evaluation generator\n",
        "      metrics=[tl.CrossEntropyLoss(), tl.Accuracy()] # CrossEntropyLoss and Accuracy\n",
        "    )\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    loop = training.Loop(TransformerLM(d_model=4,\n",
        "                                       d_ff=16,\n",
        "                                       n_layers=1,\n",
        "                                       n_heads=2,\n",
        "                                       mode='train'),\n",
        "                         train_task,\n",
        "                         eval_tasks=[eval_task],\n",
        "                         output_dir=output_dir)\n",
        "    \n",
        "    return loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYxlgBHPk_oG"
      },
      "source": [
        "Notice that the model will be trained for only 10 steps. \n",
        "\n",
        "Even with this constraint the model with the original default arguments took a very long time to finish. Because of this some parameters are changed when defining the model that is fed into the training loop in the function above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFRBTwSqRWRZ",
        "outputId": "479fd614-f4f0-4726-d23e-dff1963bd714"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/jax/_src/lib/xla_bridge.py:553: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step      1: Total number of trainable weights: 316336\n",
            "Step      1: Ran 1 train steps in 11.12 secs\n",
            "Step      1: train CrossEntropyLoss |  10.41613102\n",
            "Step      1: eval  CrossEntropyLoss |  10.41041756\n",
            "Step      1: eval          Accuracy |  0.00000000\n"
          ]
        }
      ],
      "source": [
        "# Should take around 1.5 minutes\n",
        "!rm -f ~/model/model.pkl.gz\n",
        "loop = training_loop(TransformerLM, train_batch_stream, eval_batch_stream)\n",
        "loop.run(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKrEBjmskeWa"
      },
      "source": [
        " <a name='4'></a>\n",
        " # Part 4:  Evaluation  \n",
        "\n",
        "<a name='4.1'></a>\n",
        "### 4.1 Loading in a trained model\n",
        "\n",
        "In this part you will evaluate by loading in an almost exact version of the model you coded, but we trained it for you to save you time. Please run the cell below to load in the model.\n",
        "\n",
        "As you may have already noticed the model that you trained and the pretrained model share the same overall architecture but they have different values for some of the parameters:\n",
        "\n",
        "    \n",
        "   `Original (pretrained) model: `                                 \n",
        "                                       \n",
        "    TransformerLM(vocab_size=33300, d_model=512, d_ff=2048, n_layers=6, n_heads=8, \n",
        "                   dropout=0.1, max_len=4096, ff_activation=tl.Relu)\n",
        "                   \n",
        "   `Your model:`\n",
        "   \n",
        "    TransformerLM(d_model=4, d_ff=16, n_layers=1, n_heads=2)\n",
        "   \n",
        "   **Only the parameters shown for your model were changed. The others stayed the same.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q  install transformers"
      ],
      "metadata": {
        "id": "eVmIannha0gY",
        "outputId": "8a562589-4e54-4b59-fc17-fb991e3b82e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading a Huggingface model for testing\n",
        "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "\n",
        "# text = \"Replace me by any text you'd like.\"\n",
        "# encoded_input = tokenizer(text, return_tensors='tf')\n",
        "# output = model(encoded_input)"
      ],
      "metadata": {
        "id": "wnMb2ywiagFe",
        "outputId": "7c38e7fa-acc9-4855-99df-9f3e0eaead51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298,
          "referenced_widgets": [
            "c58fcfd889824f6fb175a3f68cece6e1",
            "1116ba370ebc40e3bdea2e23a2236732",
            "dddaede2df4b4e63b72cac0e5520ac86",
            "5ac125ee008d4370a5a8401448970393",
            "f0e0e8fce36c4a429ddfa4bdd38d7e42",
            "3edec5a6a17a449c8954f394f98fe734",
            "c5265c64a6c14b8ba3454c872184d82d",
            "c425b7a110cc4097b70d4253d9820124",
            "8e1a901e628f4a3e85fc52bbc4bd6f42",
            "8718025a507643898b4ba7fee7b378c6",
            "610d9b989edf4238903682ebbfc5bba3",
            "c63d9f2f7f284ae8b86796a577e2af42",
            "24ccb0b768af494a9c433e6f07e03bd8",
            "866eec97f2904876b30a0738bdbe6fbf",
            "7e099be3ea044ba69fd22db0533502ff",
            "b7fa72d0cb024a3291bd86a33a1cf71a",
            "8b7e28c3bbb3454dacafa318b31b4dd7",
            "c93567edfd074ad9a14774fc17edc542",
            "96dde5d40ecf4e8aa997ec96afc2cab0",
            "077479027bb740399be768a06583c623",
            "93e85eb395744e8b8ab3f251e3e65539",
            "620a9d2c8dfe4f95a795beca9b28f08d",
            "99f005aaef2e457793cf993b9efbda7d",
            "47f857a652b0411ca500f0914d05044f",
            "cfcb3b76e5f344738b72b7c41f19e08c",
            "3c643fd2ee38443a9882942dccc60378",
            "88f7eeb74bda46eb9f13e4a00418d7ee",
            "7ea1e9ea30664b5285a013ad853ee822",
            "2359c79d051f4cd2bdfac28b2d104b3b",
            "d2d47eee9343448e8b66fd66383be017",
            "cf193310086840ec84600cd3a14b878a",
            "7b7d3ad0d2b84d3d94f34ce1ba2bf171",
            "f2599ec4098247e4821f3d1ced24c686",
            "09f630de7677406194ab122db7a311bf",
            "e76c049c9c894b8481c4e7e5e1eb30b0",
            "06c7f941a5aa4c7988873b0780f59fb7",
            "413a8d9f572045ed80c603b5cb2d527e",
            "b7d2f677911145989d5198860144c81c",
            "94366ed64051467a980f8cea2a9e40f1",
            "54d6ff35427b4b10a85df3b2ec23532b",
            "24e4eaf0830840998408f82328f99a12",
            "000b281ae90b453f9943ad3f2b364cbf",
            "33c9af62e477437ea40aeb12b8ce02de",
            "64d79c33e3ef442cb76f544656959a3d",
            "272049d9bcfb489aaff24f338ee8481e",
            "e6ea93257a13433c8d8d5c3307a338a9",
            "887aa9c0ebc44f93a6ca82e69eb22bc1",
            "fa758c5643184273aa3ab249d51970ba",
            "f6e6ad73b4994611ab3331a53b361596",
            "4969edfff3804b3caeb37f1cfe74a053",
            "12ff5f9467fa4b7ca5e29abb39e96408",
            "00b03f8d5e474d4aa84c10388ee4adaf",
            "09624d3f82b246439d071058d3b0415b",
            "0cc80bed4dac4e248e61700c324da65b",
            "1958c83e80674db586f0474fe8cb08e4",
            "6a75b43ca552439893299044cf1e6531",
            "bd9f83104272462198fe36a8e73b0d9a",
            "b47578f3f638487b8435fe777253ef4f",
            "e3205dcb78734b3eb8ca66cadda4dcf1",
            "6a7fbb5f663c470e9a781e04686061bc",
            "f5517d0845f44374ac896c09fa735f9b",
            "42c584ae6d714db1b6744dcc8ffcf7a3",
            "dbfb669e2a3d4c3f97f282df17611ed7",
            "d3a25d5608f9442f979e834592538bff",
            "f7917020d7d84433a602764cee3f8a4c",
            "0fc6e433566e467588b90d8b1e18d374"
          ]
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c58fcfd889824f6fb175a3f68cece6e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c63d9f2f7f284ae8b86796a577e2af42"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99f005aaef2e457793cf993b9efbda7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09f630de7677406194ab122db7a311bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)\"tf_model.h5\";:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "272049d9bcfb489aaff24f338ee8481e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBartForConditionalGeneration.\n",
            "\n",
            "All the layers of TFBartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-large-cnn.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a75b43ca552439893299044cf1e6531"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "zWoSzR5tkoAx"
      },
      "outputs": [],
      "source": [
        "# # Get the model architecture\n",
        "# model = TransformerLM(mode='eval')\n",
        "\n",
        "# # Load the pre-trained weights\n",
        "# model.init_from_file('model.pkl.gz', weights_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilM9C8P3RWRf"
      },
      "source": [
        "<a name='5'></a>\n",
        "# Part 5: Testing with your own input\n",
        "\n",
        "You will now test your input. You are going to implement greedy decoding. This consists of two functions. The first one allows you to identify the next symbol. It gets the argmax of the output of your model and then returns that index. \n",
        "\n",
        "<a name='ex06'></a>\n",
        "### Exercise 06\n",
        "**Instructions:** Implement the next symbol function that takes in the cur_output_tokens and the trained model to return the index of the next word. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "rD_bXRCpRWRg"
      },
      "outputs": [],
      "source": [
        "# UNQ_C9\n",
        "def next_symbol(cur_output_tokens, model):\n",
        "    \"\"\"Returns the next symbol for a given sentence.\n",
        "\n",
        "    Args:\n",
        "        cur_output_tokens (list): tokenized sentence with EOS and PAD tokens at the end.\n",
        "        model (trax.layers.combinators.Serial): The transformer model.\n",
        "\n",
        "    Returns:\n",
        "        int: tokenized symbol.\n",
        "    \"\"\"\n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    \n",
        "    # # current output tokens length\n",
        "    # # token_length = len(cur_output_tokens)\n",
        "    # token_length = len(cur_output_tokens)\n",
        "    # # calculate the minimum power of 2 big enough to store token_length\n",
        "    # # HINT: use np.ceil() and np.log2()\n",
        "    # # add 1 to token_length so np.log2() doesn't receive 0 when token_length is 0\n",
        "    # padded_length = 2**int(np.ceil(np.log2(token_length + 1)))\n",
        "\n",
        "    # # Fill cur_output_tokens with 0's until it reaches padded_length\n",
        "    # padded = cur_output_tokens + [0] * (padded_length - token_length)\n",
        "    # padded_with_batch = np.array(padded)[None, :] # Don't replace this 'None'! This is a way of setting the batch dim\n",
        "\n",
        "    # model expects a tuple containing two padded tensors (with batch)\n",
        "    # output, _ = model((padded_with_batch, padded_with_batch))\n",
        "    \n",
        "    token_length = cur_output_tokens['input_ids'].shape[-1] -1\n",
        "    output = model(cur_output_tokens)  \n",
        "    # HINT: output has shape (1, padded_length, vocab_size)\n",
        "    # To get log_probs you need to index output with 0 in the first dim\n",
        "    # token_length in the second dim and all of the entries for the last dim.\n",
        "    log_probs = output[0][0, token_length, :]\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return int(np.argmax(log_probs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "Dkw7rwbBk_oH",
        "outputId": "6019a429-df40-43cb-c6a4-dafaaeaeb1d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "# Test it out!\n",
        "sentence_test_nxt_symbl = \"I want to fly in the sky.\"\n",
        "# detokenize([next_symbol(tokenize(sentence_test_nxt_symbl, return_tensors='tf')+[0], model)])\n",
        "[tokenizer.decode([next_symbol(tokenizer(sentence_test_nxt_symbl, return_tensors='tf'), model)])]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7efM_uskk_oH"
      },
      "source": [
        "**Expected Output:**\n",
        "```CPP\n",
        "'The'\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AwrQFglRWRj"
      },
      "source": [
        "<a name='5.1'></a>\n",
        "### 5.1 Greedy decoding\n",
        "\n",
        "Now you will implement the greedy_decode algorithm that will call the `next_symbol` function. It takes in the input_sentence, the trained model and returns the decoded sentence. \n",
        "\n",
        "<a name='ex07'></a>\n",
        "### Exercise 07\n",
        "\n",
        "**Instructions**: Implement the greedy_decode algorithm. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentence=\"I want to fly in the sky.\"\n",
        "(tokenizer(input_sentence, return_tensors='tf'))['input_ids']"
      ],
      "metadata": {
        "id": "RWaBcyw4l4LH",
        "outputId": "1919751a-70c6-4f09-f303-482a8a8b941a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 10), dtype=int32, numpy=\n",
              "array([[   0,  100,  236,    7, 3598,   11,    5, 6360,    4,    2]],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "6HwIdimiN0k2"
      },
      "outputs": [],
      "source": [
        "# UNQ_C10\n",
        "# Decoding functions.\n",
        "def greedy_decode(input_sentence, model):\n",
        "    \"\"\"Greedy decode function.\n",
        "\n",
        "    Args:\n",
        "        input_sentence (string): a sentence or article.\n",
        "        model (trax.layers.combinators.Serial): Transformer model.\n",
        "\n",
        "    Returns:\n",
        "        string: summary of the input.\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
        "    # Use tokenize()\n",
        "    # cur_output_tokens = tokenizer(input_sentence, return_tensors='tf')\n",
        "    cur_output_tokens = tokenizer(input_sentence, return_tensors='tf')['input_ids']\n",
        "    generated_output = [] \n",
        "    cur_output = 0 \n",
        "    EOS = 1 \n",
        "    \n",
        "    while cur_output != EOS:\n",
        "        # Get next symbol\n",
        "        cur_output = next_symbol(tokenizer(input_sentence, return_tensors='tf'), model)\n",
        "        # Append next symbol to original sentence\n",
        "        cur_output_tokens + (cur_output)\n",
        "        # Append next symbol to generated sentence\n",
        "        generated_output.append(cur_output)\n",
        "        print(tokenizer.decode(generated_output))\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return tokenizer.decode(generated_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9kHuIDGW1sOr",
        "outputId": "d0950ab4-7a6c-4d7e-af24-e7733a8d4e2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my name is Ramanathan Goenka, I would love to visit new places \n",
            "\n",
            ".\n",
            "..\n",
            "...\n",
            "....\n",
            ".....\n",
            "......\n",
            ".......\n",
            "........\n",
            ".........\n",
            "..........\n",
            "...........\n",
            "............\n",
            ".............\n",
            "..............\n",
            "...............\n",
            "................\n",
            ".................\n",
            "..................\n",
            "...................\n",
            "....................\n",
            ".....................\n",
            "......................\n",
            ".......................\n",
            "........................\n",
            ".........................\n",
            "..........................\n",
            "...........................\n",
            "............................\n",
            ".............................\n",
            "..............................\n",
            "...............................\n",
            "................................\n",
            ".................................\n",
            "..................................\n",
            "...................................\n",
            "....................................\n",
            ".....................................\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-6f246c63b310>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"my name is Ramanathan Goenka, I would love to visit new places\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgreedy_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-80-47c3e524f4f3>\u001b[0m in \u001b[0;36mgreedy_decode\u001b[0;34m(input_sentence, model)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mcur_output\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEOS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Get next symbol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mcur_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_symbol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Append next symbol to original sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mcur_output_tokens\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcur_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-77-8ecca25f72e7>\u001b[0m in \u001b[0;36mnext_symbol\u001b[0;34m(cur_output_tokens, model)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtoken_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur_output_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_output_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;31m# HINT: output has shape (1, padded_length, vocab_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# To get log_probs you need to index output with 0 in the first dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_in_current_and_subclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1130\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                 ):\n\u001b[0;32m-> 1132\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mrun_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0munpacked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_args_and_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munpacked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;31m# Keras enforces the first layer argument to be passed, and checks it through `inspect.getfullargspec()`. This\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bart/modeling_tf_bart.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, decoder_position_ids, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, labels, training)\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m         )\n\u001b[0;32m-> 1396\u001b[0;31m         \u001b[0mlm_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1397\u001b[0m         \u001b[0mlm_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m         \u001b[0mmasked_lm_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhf_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlm_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[1;32m   3631\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3632\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_resource_variable_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3633\u001b[0;31m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3634\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3635\u001b[0m       \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpreferred_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1618\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1619\u001b[0;31m         ret = conversion_func(\n\u001b[0m\u001b[1;32m   1620\u001b[0m             value, dtype=preferred_dtype, name=name, as_ref=as_ref)\n\u001b[1;32m   1621\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1587\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1588\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cast_nested_seqs_to_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1589\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_autopacking_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"packed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_helper\u001b[0;34m(list_or_tuple, dtype, name)\u001b[0m\n\u001b[1;32m   1494\u001b[0m     \u001b[0;31m# checking.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_or_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_or_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1497\u001b[0m   \u001b[0mmust_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m   \u001b[0mconverted_elems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mpack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   6547\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6548\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6549\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   6550\u001b[0m         _ctx, \"Pack\", name, values, \"axis\", axis)\n\u001b[1;32m   6551\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Test it out on a sentence!\n",
        "test_sentence = \"my name is Ramanathan Goenka, I would love to visit new places\"\n",
        "print(wrapper.fill(test_sentence), '\\n')\n",
        "print(greedy_decode(test_sentence, model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA-279WI2D3G"
      },
      "source": [
        "**Expected Output:**\n",
        "```CPP\n",
        ":\n",
        ": I\n",
        ": I just\n",
        ": I just found\n",
        ": I just found ros\n",
        ": I just found roses\n",
        ": I just found roses,\n",
        ": I just found roses, not\n",
        ": I just found roses, not tu\n",
        ": I just found roses, not tulips\n",
        ": I just found roses, not tulips\n",
        ": I just found roses, not tulips.\n",
        ": I just found roses, not tulips.<EOS>\n",
        ": I just found roses, not tulips.<EOS>\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "id": "DYgX-mzjyUia",
        "outputId": "77c39111-cc2b-435a-b6cc-860509214eed",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It’s the posing craze sweeping the U.S. after being brought to fame by\n",
            "skier Lindsey Vonn, soccer star Omar Cummings, baseball player Albert\n",
            "Pujols - and even Republican politician Rick Perry. But now four\n",
            "students at Riverhead High School on Long Island, New York, have been\n",
            "suspended for dropping to a knee and taking up a prayer pose to mimic\n",
            "Denver Broncos quarterback Tim Tebow. Jordan Fulcoly, Wayne Drexel,\n",
            "Tyler Carroll and Connor Carroll were all suspended for one day\n",
            "because the ‘Tebowing’ craze was blocking the hallway and presenting a\n",
            "safety hazard to students. Scroll down for video. Banned: Jordan\n",
            "Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll (all pictured\n",
            "left) were all suspended for one day by Riverhead High School on Long\n",
            "Island, New York, for their tribute to Broncos quarterback Tim Tebow.\n",
            "Issue: Four of the pupils were suspended for one day because they\n",
            "allegedly did not heed to warnings that the 'Tebowing' craze at the\n",
            "school was blocking the hallway and presenting a safety hazard to\n",
            "students. \n",
            "\n",
            "</s>\n",
            "</s></s>\n",
            "</s></s></s>\n",
            "</s></s></s></s>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-45270e4a2a27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0marticle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"It’s the posing craze sweeping the U.S. after being brought to fame by skier Lindsey Vonn, soccer star Omar Cummings, baseball player Albert Pujols - and even Republican politician Rick Perry. But now four students at Riverhead High School on Long Island, New York, have been suspended for dropping to a knee and taking up a prayer pose to mimic Denver Broncos quarterback Tim Tebow. Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were all suspended for one day because the ‘Tebowing’ craze was blocking the hallway and presenting a safety hazard to students. Scroll down for video. Banned: Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll (all pictured left) were all suspended for one day by Riverhead High School on Long Island, New York, for their tribute to Broncos quarterback Tim Tebow. Issue: Four of the pupils were suspended for one day because they allegedly did not heed to warnings that the 'Tebowing' craze at the school was blocking the hallway and presenting a safety hazard to students.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgreedy_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-57-47c3e524f4f3>\u001b[0m in \u001b[0;36mgreedy_decode\u001b[0;34m(input_sentence, model)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mcur_output\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEOS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Get next symbol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mcur_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_symbol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Append next symbol to original sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mcur_output_tokens\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcur_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-8ecca25f72e7>\u001b[0m in \u001b[0;36mnext_symbol\u001b[0;34m(cur_output_tokens, model)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtoken_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur_output_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_output_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;31m# HINT: output has shape (1, padded_length, vocab_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# To get log_probs you need to index output with 0 in the first dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_in_current_and_subclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1130\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                 ):\n\u001b[0;32m-> 1132\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mrun_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0munpacked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_args_and_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munpacked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;31m# Keras enforces the first layer argument to be passed, and checks it through `inspect.getfullargspec()`. This\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bart/modeling_tf_bart.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, decoder_position_ids, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, labels, training)\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 )\n\u001b[1;32m   1376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1378\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1130\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                 ):\n\u001b[0;32m-> 1132\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mrun_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0munpacked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_args_and_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munpacked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;31m# Keras enforces the first layer argument to be passed, and checks it through `inspect.getfullargspec()`. This\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bart/modeling_tf_bart.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, decoder_position_ids, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, training, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoder_outputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m             encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1131\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1130\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                 ):\n\u001b[0;32m-> 1132\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mrun_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0munpacked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_args_and_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munpacked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;31m# Keras enforces the first layer argument to be passed, and checks it through `inspect.getfullargspec()`. This\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bart/modeling_tf_bart.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, inputs_embeds, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m    812\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m             hidden_states, attn = encoder_layer(\n\u001b[0m\u001b[1;32m    815\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1130\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                 ):\n\u001b[0;32m-> 1132\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bart/modeling_tf_bart.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, training)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/activations.py\u001b[0m in \u001b[0;36mgelu\u001b[0;34m(x, approximate)\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0;34m-\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mGaussian\u001b[0m \u001b[0mError\u001b[0m \u001b[0mLinear\u001b[0m \u001b[0mUnits\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mGELUs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0marxiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1606.08415\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \"\"\"\n\u001b[0;32m--> 359\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapproximate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mgelu\u001b[0;34m(features, approximate, name)\u001b[0m\n\u001b[1;32m   3741\u001b[0m                               (features + coeff * math_ops.pow(features, 3))))\n\u001b[1;32m   3742\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3743\u001b[0;31m       return 0.5 * features * (1.0 + math_ops.erf(\n\u001b[0m\u001b[1;32m   3744\u001b[0m           features / math_ops.cast(1.4142135623730951, features.dtype)))\n\u001b[1;32m   3745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mr_binary_op_wrapper\u001b[0;34m(y, x)\u001b[0m\n\u001b[1;32m   1440\u001b[0m       \u001b[0;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m   \u001b[0;31m# Propagate func.__doc__ to the wrappers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1765\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1767\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    527\u001b[0m   \"\"\"\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6575\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6576\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6577\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   6578\u001b[0m         _ctx, \"Mul\", name, x, y)\n\u001b[1;32m   6579\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Test it out with a whole article!\n",
        "article = \"It’s the posing craze sweeping the U.S. after being brought to fame by skier Lindsey Vonn, soccer star Omar Cummings, baseball player Albert Pujols - and even Republican politician Rick Perry. But now four students at Riverhead High School on Long Island, New York, have been suspended for dropping to a knee and taking up a prayer pose to mimic Denver Broncos quarterback Tim Tebow. Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were all suspended for one day because the ‘Tebowing’ craze was blocking the hallway and presenting a safety hazard to students. Scroll down for video. Banned: Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll (all pictured left) were all suspended for one day by Riverhead High School on Long Island, New York, for their tribute to Broncos quarterback Tim Tebow. Issue: Four of the pupils were suspended for one day because they allegedly did not heed to warnings that the 'Tebowing' craze at the school was blocking the hallway and presenting a safety hazard to students.\"\n",
        "print(wrapper.fill(article), '\\n')\n",
        "print(greedy_decode(article, model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNq0cBIFk_oJ"
      },
      "source": [
        "**Expected Output:**\n",
        "```CPP\n",
        "Jordan\n",
        "Jordan Ful\n",
        "Jordan Fulcol\n",
        "Jordan Fulcoly\n",
        "Jordan Fulcoly,\n",
        "Jordan Fulcoly, Wayne\n",
        "Jordan Fulcoly, Wayne Dre\n",
        "Jordan Fulcoly, Wayne Drexe\n",
        "Jordan Fulcoly, Wayne Drexel\n",
        "Jordan Fulcoly, Wayne Drexel,\n",
        ".\n",
        ".\n",
        ".\n",
        "\n",
        "Final summary:\n",
        "\n",
        "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
        "suspended for one day. Four students were suspended for one day\n",
        "because they allegedly did not heed to warnings that the 'Tebowing'\n",
        "craze was blocking the hallway and presenting a safety hazard to\n",
        "students.<EOS>\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Fp6euVrk_oK"
      },
      "source": [
        "**Congratulations on finishing this week's assignment!** You did a lot of work and now you should have a better understanding of the encoder part of Transformers and how Transformers can be used for text summarization.\n",
        "\n",
        "**Keep it up!**"
      ]
    }
  ],
  "metadata": {
    "coursera": {
      "schema_names": [
        "NLPC4-2"
      ]
    },
    "jupytext": {
      "encoding": "# -*- coding: utf-8 -*-",
      "formats": "ipynb,py:percent"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c58fcfd889824f6fb175a3f68cece6e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1116ba370ebc40e3bdea2e23a2236732",
              "IPY_MODEL_dddaede2df4b4e63b72cac0e5520ac86",
              "IPY_MODEL_5ac125ee008d4370a5a8401448970393"
            ],
            "layout": "IPY_MODEL_f0e0e8fce36c4a429ddfa4bdd38d7e42"
          }
        },
        "1116ba370ebc40e3bdea2e23a2236732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3edec5a6a17a449c8954f394f98fe734",
            "placeholder": "​",
            "style": "IPY_MODEL_c5265c64a6c14b8ba3454c872184d82d",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "dddaede2df4b4e63b72cac0e5520ac86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c425b7a110cc4097b70d4253d9820124",
            "max": 1585,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e1a901e628f4a3e85fc52bbc4bd6f42",
            "value": 1585
          }
        },
        "5ac125ee008d4370a5a8401448970393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8718025a507643898b4ba7fee7b378c6",
            "placeholder": "​",
            "style": "IPY_MODEL_610d9b989edf4238903682ebbfc5bba3",
            "value": " 1.58k/1.58k [00:00&lt;00:00, 20.8kB/s]"
          }
        },
        "f0e0e8fce36c4a429ddfa4bdd38d7e42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3edec5a6a17a449c8954f394f98fe734": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5265c64a6c14b8ba3454c872184d82d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c425b7a110cc4097b70d4253d9820124": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e1a901e628f4a3e85fc52bbc4bd6f42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8718025a507643898b4ba7fee7b378c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "610d9b989edf4238903682ebbfc5bba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c63d9f2f7f284ae8b86796a577e2af42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24ccb0b768af494a9c433e6f07e03bd8",
              "IPY_MODEL_866eec97f2904876b30a0738bdbe6fbf",
              "IPY_MODEL_7e099be3ea044ba69fd22db0533502ff"
            ],
            "layout": "IPY_MODEL_b7fa72d0cb024a3291bd86a33a1cf71a"
          }
        },
        "24ccb0b768af494a9c433e6f07e03bd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b7e28c3bbb3454dacafa318b31b4dd7",
            "placeholder": "​",
            "style": "IPY_MODEL_c93567edfd074ad9a14774fc17edc542",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "866eec97f2904876b30a0738bdbe6fbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96dde5d40ecf4e8aa997ec96afc2cab0",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_077479027bb740399be768a06583c623",
            "value": 898823
          }
        },
        "7e099be3ea044ba69fd22db0533502ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93e85eb395744e8b8ab3f251e3e65539",
            "placeholder": "​",
            "style": "IPY_MODEL_620a9d2c8dfe4f95a795beca9b28f08d",
            "value": " 899k/899k [00:00&lt;00:00, 2.43MB/s]"
          }
        },
        "b7fa72d0cb024a3291bd86a33a1cf71a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b7e28c3bbb3454dacafa318b31b4dd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c93567edfd074ad9a14774fc17edc542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96dde5d40ecf4e8aa997ec96afc2cab0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "077479027bb740399be768a06583c623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93e85eb395744e8b8ab3f251e3e65539": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "620a9d2c8dfe4f95a795beca9b28f08d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99f005aaef2e457793cf993b9efbda7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47f857a652b0411ca500f0914d05044f",
              "IPY_MODEL_cfcb3b76e5f344738b72b7c41f19e08c",
              "IPY_MODEL_3c643fd2ee38443a9882942dccc60378"
            ],
            "layout": "IPY_MODEL_88f7eeb74bda46eb9f13e4a00418d7ee"
          }
        },
        "47f857a652b0411ca500f0914d05044f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ea1e9ea30664b5285a013ad853ee822",
            "placeholder": "​",
            "style": "IPY_MODEL_2359c79d051f4cd2bdfac28b2d104b3b",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "cfcb3b76e5f344738b72b7c41f19e08c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2d47eee9343448e8b66fd66383be017",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf193310086840ec84600cd3a14b878a",
            "value": 456318
          }
        },
        "3c643fd2ee38443a9882942dccc60378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b7d3ad0d2b84d3d94f34ce1ba2bf171",
            "placeholder": "​",
            "style": "IPY_MODEL_f2599ec4098247e4821f3d1ced24c686",
            "value": " 456k/456k [00:00&lt;00:00, 1.51MB/s]"
          }
        },
        "88f7eeb74bda46eb9f13e4a00418d7ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ea1e9ea30664b5285a013ad853ee822": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2359c79d051f4cd2bdfac28b2d104b3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2d47eee9343448e8b66fd66383be017": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf193310086840ec84600cd3a14b878a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b7d3ad0d2b84d3d94f34ce1ba2bf171": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2599ec4098247e4821f3d1ced24c686": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09f630de7677406194ab122db7a311bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e76c049c9c894b8481c4e7e5e1eb30b0",
              "IPY_MODEL_06c7f941a5aa4c7988873b0780f59fb7",
              "IPY_MODEL_413a8d9f572045ed80c603b5cb2d527e"
            ],
            "layout": "IPY_MODEL_b7d2f677911145989d5198860144c81c"
          }
        },
        "e76c049c9c894b8481c4e7e5e1eb30b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94366ed64051467a980f8cea2a9e40f1",
            "placeholder": "​",
            "style": "IPY_MODEL_54d6ff35427b4b10a85df3b2ec23532b",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "06c7f941a5aa4c7988873b0780f59fb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24e4eaf0830840998408f82328f99a12",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_000b281ae90b453f9943ad3f2b364cbf",
            "value": 1355863
          }
        },
        "413a8d9f572045ed80c603b5cb2d527e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33c9af62e477437ea40aeb12b8ce02de",
            "placeholder": "​",
            "style": "IPY_MODEL_64d79c33e3ef442cb76f544656959a3d",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 3.64MB/s]"
          }
        },
        "b7d2f677911145989d5198860144c81c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94366ed64051467a980f8cea2a9e40f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54d6ff35427b4b10a85df3b2ec23532b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24e4eaf0830840998408f82328f99a12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "000b281ae90b453f9943ad3f2b364cbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33c9af62e477437ea40aeb12b8ce02de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64d79c33e3ef442cb76f544656959a3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "272049d9bcfb489aaff24f338ee8481e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6ea93257a13433c8d8d5c3307a338a9",
              "IPY_MODEL_887aa9c0ebc44f93a6ca82e69eb22bc1",
              "IPY_MODEL_fa758c5643184273aa3ab249d51970ba"
            ],
            "layout": "IPY_MODEL_f6e6ad73b4994611ab3331a53b361596"
          }
        },
        "e6ea93257a13433c8d8d5c3307a338a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4969edfff3804b3caeb37f1cfe74a053",
            "placeholder": "​",
            "style": "IPY_MODEL_12ff5f9467fa4b7ca5e29abb39e96408",
            "value": "Downloading (…)&quot;tf_model.h5&quot;;: 100%"
          }
        },
        "887aa9c0ebc44f93a6ca82e69eb22bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00b03f8d5e474d4aa84c10388ee4adaf",
            "max": 1625692088,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09624d3f82b246439d071058d3b0415b",
            "value": 1625692088
          }
        },
        "fa758c5643184273aa3ab249d51970ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cc80bed4dac4e248e61700c324da65b",
            "placeholder": "​",
            "style": "IPY_MODEL_1958c83e80674db586f0474fe8cb08e4",
            "value": " 1.63G/1.63G [00:27&lt;00:00, 49.8MB/s]"
          }
        },
        "f6e6ad73b4994611ab3331a53b361596": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4969edfff3804b3caeb37f1cfe74a053": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12ff5f9467fa4b7ca5e29abb39e96408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00b03f8d5e474d4aa84c10388ee4adaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09624d3f82b246439d071058d3b0415b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0cc80bed4dac4e248e61700c324da65b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1958c83e80674db586f0474fe8cb08e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a75b43ca552439893299044cf1e6531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd9f83104272462198fe36a8e73b0d9a",
              "IPY_MODEL_b47578f3f638487b8435fe777253ef4f",
              "IPY_MODEL_e3205dcb78734b3eb8ca66cadda4dcf1"
            ],
            "layout": "IPY_MODEL_6a7fbb5f663c470e9a781e04686061bc"
          }
        },
        "bd9f83104272462198fe36a8e73b0d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5517d0845f44374ac896c09fa735f9b",
            "placeholder": "​",
            "style": "IPY_MODEL_42c584ae6d714db1b6744dcc8ffcf7a3",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "b47578f3f638487b8435fe777253ef4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbfb669e2a3d4c3f97f282df17611ed7",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3a25d5608f9442f979e834592538bff",
            "value": 363
          }
        },
        "e3205dcb78734b3eb8ca66cadda4dcf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7917020d7d84433a602764cee3f8a4c",
            "placeholder": "​",
            "style": "IPY_MODEL_0fc6e433566e467588b90d8b1e18d374",
            "value": " 363/363 [00:00&lt;00:00, 11.3kB/s]"
          }
        },
        "6a7fbb5f663c470e9a781e04686061bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5517d0845f44374ac896c09fa735f9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42c584ae6d714db1b6744dcc8ffcf7a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbfb669e2a3d4c3f97f282df17611ed7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3a25d5608f9442f979e834592538bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7917020d7d84433a602764cee3f8a4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fc6e433566e467588b90d8b1e18d374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}